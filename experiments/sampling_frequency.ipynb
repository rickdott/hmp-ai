{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Sampling Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Will a model trained using HMP data from a HMP model fitted on a lower sampling frequency perform worse?\n",
    "\n",
    "**Hypothesis**: I think so, but the degree of worsening is dependent on the type of model, a CNN will be worsened less than an RNN, as an RNN uses this lost temporal information more.\n",
    "\n",
    "**Result**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from hmpai.utilities import print_results\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.pytorch.training import k_fold_cross_validate\n",
    "from hmpai.normalization import *\n",
    "\n",
    "n_folds = 25\n",
    "logs_path = Path(\"../logs/exp_sampling_frequency/\")\n",
    "normalization_fn = norm_min1_to_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: 500 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/sat1/split_stage_data.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07d751c94c14331b81e6c14d48674ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_channels\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mchannels),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_samples\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39msamples),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_classes\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mlabels),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m }\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m train_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogs_path\u001b[39m\u001b[39m\"\u001b[39m: logs_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madditional_info\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39msampling_frequency\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m500hz_cnn\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madditional_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m500hz_cnn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m results \u001b[39m=\u001b[39m k_fold_cross_validate(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     model,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model_kwargs,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     data,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     n_folds,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     train_kwargs\u001b[39m=\u001b[39;49mtrain_kwargs,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     normalization_fn\u001b[39m=\u001b[39;49mnormalization_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/experiments/sampling_frequency.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m print_results(results)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/training.py:223\u001b[0m, in \u001b[0;36mk_fold_cross_validate\u001b[0;34m(model, model_kwargs, data, k, batch_size, epochs, normalization_fn, gen_kwargs, train_kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     train_kwargs[\u001b[39m\"\u001b[39m\u001b[39madditional_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m additional_name\n\u001b[1;32m    222\u001b[0m \u001b[39m# Train and test model\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m result \u001b[39m=\u001b[39m train_and_test(\n\u001b[1;32m    224\u001b[0m     model_instance,\n\u001b[1;32m    225\u001b[0m     train_dataset,\n\u001b[1;32m    226\u001b[0m     test_dataset,\n\u001b[1;32m    227\u001b[0m     val_set\u001b[39m=\u001b[39;49mtest_dataset,\n\u001b[1;32m    228\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    229\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    230\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_kwargs,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m{\u001b[39;00mi_fold\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m{\u001b[39;00mi_fold\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: F1-Score: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m'\u001b[39m\u001b[39mmacro avg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mf1-score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/training.py:108\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, train_set, test_set, val_set, batch_size, epochs, workers, logs_path, additional_info, additional_name, use_class_weights)\u001b[0m\n\u001b[1;32m    105\u001b[0m tepoch\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[39m# Train on batches in train_loader\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m batch_losses \u001b[39m=\u001b[39m train(model, train_loader, opt, loss, tepoch)\n\u001b[1;32m    110\u001b[0m \u001b[39m# Validate model and communicate results\u001b[39;00m\n\u001b[1;32m    111\u001b[0m val_losses, val_accuracy \u001b[39m=\u001b[39m validate(model, val_loader, loss)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/training.py:264\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss_function, progress)\u001b[0m\n\u001b[1;32m    260\u001b[0m loss_per_batch \u001b[39m=\u001b[39m []\n\u001b[1;32m    262\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    263\u001b[0m     \u001b[39m# (Index, samples, channels), (Index, )\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     data, labels \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE), batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m    266\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    268\u001b[0m     predictions \u001b[39m=\u001b[39m model(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SAT1Deep\n",
    "model_kwargs = {\n",
    "    \"n_channels\": len(data.channels),\n",
    "    \"n_samples\": len(data.samples),\n",
    "    \"n_classes\": len(data.labels),\n",
    "}\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"sampling_frequency\": \"500hz_cnn\"},\n",
    "    \"additional_name\": f\"500hz_cnn\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    model,\n",
    "    model_kwargs,\n",
    "    data,\n",
    "    n_folds,\n",
    "    train_kwargs=train_kwargs,\n",
    "    normalization_fn=normalization_fn,\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1GRU\n",
    "model_kwargs = {\n",
    "    \"n_channels\": len(data.channels),\n",
    "    \"n_samples\": len(data.samples),\n",
    "    \"n_classes\": len(data.labels),\n",
    "}\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"sampling_frequency\": \"500hz_rnn\"},\n",
    "    \"additional_name\": f\"500hz_rnn\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    model,\n",
    "    model_kwargs,\n",
    "    data,\n",
    "    n_folds,\n",
    "    train_kwargs=train_kwargs,\n",
    "    normalization_fn=normalization_fn,\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: 100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/sat1/split_stage_data_100hz.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1Base\n",
    "model_kwargs = {\n",
    "    \"n_channels\": len(data.channels),\n",
    "    \"n_samples\": len(data.samples),\n",
    "    \"n_classes\": len(data.labels),\n",
    "}\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"sampling_frequency\": \"100hz_cnn\"},\n",
    "    \"additional_name\": f\"100hz_cnn\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    model,\n",
    "    model_kwargs,\n",
    "    data,\n",
    "    n_folds,\n",
    "    train_kwargs=train_kwargs,\n",
    "    normalization_fn=normalization_fn,\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1GRU\n",
    "model_kwargs = {\n",
    "    \"n_channels\": len(data.channels),\n",
    "    \"n_samples\": len(data.samples),\n",
    "    \"n_classes\": len(data.labels),\n",
    "}\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"sampling_frequency\": \"100hz_rnn\"},\n",
    "    \"additional_name\": f\"100hz_rnn\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    model,\n",
    "    model_kwargs,\n",
    "    data,\n",
    "    n_folds,\n",
    "    train_kwargs=train_kwargs,\n",
    "    normalization_fn=normalization_fn,\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results in Tensorboard\n",
    "! tensorboard --logdir logs/exp_sampling_frequency/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
