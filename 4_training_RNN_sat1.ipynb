{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 08:51:21.601615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 08:51:22.150167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from shared.models import *\n",
    "from shared.utilities import *\n",
    "from shared.training import train_and_evaluate, split_data_on_participants, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.generators import *\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_weighted_mean.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_data_on_participants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/4_training_RNN_sat1.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/4_training_RNN_sat1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_data, val_data, test_data \u001b[39m=\u001b[39m split_data_on_participants(data, \u001b[39m60\u001b[39m, norm_dummy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_data_on_participants' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = split_data_on_participants(data, 60, norm_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 16:46:53.731024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:53.760552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:53.760714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:53.762505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:53.762578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:53.762641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:54.436576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:54.436671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:54.436683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-19 16:46:54.436750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-19 16:46:54.436761: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-19 16:46:54.436766: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-19 16:46:54.436862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = SAT1LSTM(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 16:47:09.574856: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2023-10-19 16:47:10.614493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-19 16:47:10.700786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-19 16:47:10.950217: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5593a5d66fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-19 16:47:10.950256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-19 16:47:10.956250: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-19 16:47:11.068437: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 24s 19ms/step - loss: 5.0982 - accuracy: 0.5977 - val_loss: 0.7599 - val_accuracy: 0.7133\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 3.0389 - accuracy: 0.7666 - val_loss: 0.6398 - val_accuracy: 0.7721\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 2.5429 - accuracy: 0.8008 - val_loss: 0.5297 - val_accuracy: 0.8059\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 2.2976 - accuracy: 0.8245 - val_loss: 0.6301 - val_accuracy: 0.7729\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 2.1559 - accuracy: 0.8362 - val_loss: 0.5227 - val_accuracy: 0.8014\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.9998 - accuracy: 0.8495 - val_loss: 0.4943 - val_accuracy: 0.8199\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.9522 - accuracy: 0.8493 - val_loss: 0.5090 - val_accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.8920 - accuracy: 0.8537 - val_loss: 0.4736 - val_accuracy: 0.8270\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 19s 18ms/step - loss: 1.7951 - accuracy: 0.8627 - val_loss: 0.4565 - val_accuracy: 0.8270\n",
      "Epoch 10/20\n",
      "997/997 [==============================] - 19s 19ms/step - loss: 1.7193 - accuracy: 0.8689 - val_loss: 0.5015 - val_accuracy: 0.8238\n",
      "Epoch 11/20\n",
      "997/997 [==============================] - 19s 18ms/step - loss: 1.6283 - accuracy: 0.8763 - val_loss: 0.4982 - val_accuracy: 0.8130\n",
      "Epoch 12/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.5852 - accuracy: 0.8796 - val_loss: 0.4689 - val_accuracy: 0.8381\n",
      "254/254 [==============================] - 4s 11ms/step\n",
      "Fold 1: accuracy: 0.8270177165354331\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "995/995 [==============================] - 19s 18ms/step - loss: 5.1527 - accuracy: 0.5957 - val_loss: 0.7202 - val_accuracy: 0.7261\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 3.0150 - accuracy: 0.7693 - val_loss: 0.5436 - val_accuracy: 0.8015\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 2.5612 - accuracy: 0.8034 - val_loss: 0.5472 - val_accuracy: 0.7981\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 2.3394 - accuracy: 0.8222 - val_loss: 0.5115 - val_accuracy: 0.8164\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 2.1789 - accuracy: 0.8312 - val_loss: 0.4601 - val_accuracy: 0.8362\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 2.0465 - accuracy: 0.8445 - val_loss: 0.4611 - val_accuracy: 0.8318\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 1.9708 - accuracy: 0.8473 - val_loss: 0.4712 - val_accuracy: 0.8259\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 18s 18ms/step - loss: 1.8928 - accuracy: 0.8557 - val_loss: 0.4846 - val_accuracy: 0.8254\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Fold 2: accuracy: 0.836181640625\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 5.1917 - accuracy: 0.5986 - val_loss: 0.7880 - val_accuracy: 0.7041\n",
      "Epoch 2/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 3.1730 - accuracy: 0.7614 - val_loss: 0.5663 - val_accuracy: 0.7826\n",
      "Epoch 3/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 2.5684 - accuracy: 0.8101 - val_loss: 0.5317 - val_accuracy: 0.8085\n",
      "Epoch 4/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 2.3703 - accuracy: 0.8207 - val_loss: 0.4891 - val_accuracy: 0.8148\n",
      "Epoch 5/20\n",
      "1002/1002 [==============================] - 18s 18ms/step - loss: 2.1678 - accuracy: 0.8340 - val_loss: 0.4825 - val_accuracy: 0.8205\n",
      "Epoch 6/20\n",
      "1002/1002 [==============================] - 18s 18ms/step - loss: 2.0298 - accuracy: 0.8444 - val_loss: 0.4621 - val_accuracy: 0.8253\n",
      "Epoch 7/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 1.9431 - accuracy: 0.8532 - val_loss: 0.4957 - val_accuracy: 0.8168\n",
      "Epoch 8/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 1.8695 - accuracy: 0.8588 - val_loss: 0.4749 - val_accuracy: 0.8185\n",
      "Epoch 9/20\n",
      "1002/1002 [==============================] - 19s 18ms/step - loss: 1.7606 - accuracy: 0.8688 - val_loss: 0.4725 - val_accuracy: 0.8238\n",
      "249/249 [==============================] - 3s 12ms/step\n",
      "Fold 3: accuracy: 0.8253012048192772\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 5.2635 - accuracy: 0.5896 - val_loss: 0.7075 - val_accuracy: 0.7334\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 3.0873 - accuracy: 0.7694 - val_loss: 0.5286 - val_accuracy: 0.7972\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 18s 18ms/step - loss: 2.5919 - accuracy: 0.8071 - val_loss: 0.4796 - val_accuracy: 0.8211\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 2.3408 - accuracy: 0.8257 - val_loss: 0.4932 - val_accuracy: 0.8076\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 2.2149 - accuracy: 0.8347 - val_loss: 0.5022 - val_accuracy: 0.8125\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 2.0800 - accuracy: 0.8442 - val_loss: 0.4629 - val_accuracy: 0.8242\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.9609 - accuracy: 0.8499 - val_loss: 0.4765 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.8726 - accuracy: 0.8598 - val_loss: 0.4354 - val_accuracy: 0.8348\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.7605 - accuracy: 0.8699 - val_loss: 0.4712 - val_accuracy: 0.8273\n",
      "Epoch 10/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.6543 - accuracy: 0.8759 - val_loss: 0.4345 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.5892 - accuracy: 0.8801 - val_loss: 0.5074 - val_accuracy: 0.8177\n",
      "Epoch 12/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.5206 - accuracy: 0.8879 - val_loss: 0.4492 - val_accuracy: 0.8402\n",
      "Epoch 13/20\n",
      "1011/1011 [==============================] - 19s 18ms/step - loss: 1.4560 - accuracy: 0.8909 - val_loss: 0.4515 - val_accuracy: 0.8364\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8399896265560166\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 5.4899 - accuracy: 0.5720 - val_loss: 0.8231 - val_accuracy: 0.6902\n",
      "Epoch 2/20\n",
      "1001/1001 [==============================] - 18s 18ms/step - loss: 3.4689 - accuracy: 0.7368 - val_loss: 0.6514 - val_accuracy: 0.7590\n",
      "Epoch 3/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 2.7541 - accuracy: 0.7898 - val_loss: 0.5412 - val_accuracy: 0.8075\n",
      "Epoch 4/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 2.4256 - accuracy: 0.8155 - val_loss: 0.5136 - val_accuracy: 0.8133\n",
      "Epoch 5/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 2.3090 - accuracy: 0.8266 - val_loss: 0.4833 - val_accuracy: 0.8255\n",
      "Epoch 6/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 2.1138 - accuracy: 0.8390 - val_loss: 0.5034 - val_accuracy: 0.8255\n",
      "Epoch 7/20\n",
      "1001/1001 [==============================] - 19s 18ms/step - loss: 2.0069 - accuracy: 0.8497 - val_loss: 0.4591 - val_accuracy: 0.8345\n",
      "Epoch 8/20\n",
      "1001/1001 [==============================] - 18s 18ms/step - loss: 1.9261 - accuracy: 0.8555 - val_loss: 0.4970 - val_accuracy: 0.8080\n",
      "Epoch 9/20\n",
      "1001/1001 [==============================] - 18s 18ms/step - loss: 1.8383 - accuracy: 0.8582 - val_loss: 0.4677 - val_accuracy: 0.8282\n",
      "Epoch 10/20\n",
      "1001/1001 [==============================] - 18s 18ms/step - loss: 1.7389 - accuracy: 0.8656 - val_loss: 0.4724 - val_accuracy: 0.8280\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.8345\n",
      "Average Accuracy: 0.8325980377071452\n",
      "Average F1-Score: 0.8334901216571039\n"
     ]
    }
   ],
   "source": [
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs={\"logs_path\": Path(\"logs/rnn_performance\"), \"additional_name\": \"LSTM\"},\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1GRU(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n",
      "997/997 [==============================] - 22s 19ms/step - loss: 4.9468 - accuracy: 0.6175 - val_loss: 0.6330 - val_accuracy: 0.7692\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 3.2070 - accuracy: 0.7583 - val_loss: 0.5532 - val_accuracy: 0.7998\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 2.3790 - accuracy: 0.8205 - val_loss: 0.5010 - val_accuracy: 0.8227\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 2.1031 - accuracy: 0.8378 - val_loss: 0.4961 - val_accuracy: 0.8110\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.9533 - accuracy: 0.8501 - val_loss: 0.4834 - val_accuracy: 0.8294\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.8265 - accuracy: 0.8586 - val_loss: 0.4482 - val_accuracy: 0.8411\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.7975 - accuracy: 0.8621 - val_loss: 0.4642 - val_accuracy: 0.8354\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.6758 - accuracy: 0.8718 - val_loss: 0.4489 - val_accuracy: 0.8444\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.6655 - accuracy: 0.8722 - val_loss: 0.4386 - val_accuracy: 0.8461\n",
      "Epoch 10/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.5896 - accuracy: 0.8758 - val_loss: 0.4399 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.5331 - accuracy: 0.8829 - val_loss: 0.4319 - val_accuracy: 0.8513\n",
      "Epoch 12/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.5085 - accuracy: 0.8836 - val_loss: 0.4517 - val_accuracy: 0.8523\n",
      "Epoch 13/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.4429 - accuracy: 0.8888 - val_loss: 0.4978 - val_accuracy: 0.8354\n",
      "Epoch 14/20\n",
      "997/997 [==============================] - 18s 18ms/step - loss: 1.3992 - accuracy: 0.8946 - val_loss: 0.4608 - val_accuracy: 0.8481\n",
      "251/251 [==============================] - 3s 11ms/step\n",
      "Fold 1: accuracy: 0.8513446215139442\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 4.9760 - accuracy: 0.6224 - val_loss: 0.6272 - val_accuracy: 0.7825\n",
      "Epoch 2/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 2.8041 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.8135\n",
      "Epoch 3/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 2.3527 - accuracy: 0.8207 - val_loss: 0.4241 - val_accuracy: 0.8472\n",
      "Epoch 4/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 2.1368 - accuracy: 0.8357 - val_loss: 0.4442 - val_accuracy: 0.8408\n",
      "Epoch 5/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.9909 - accuracy: 0.8497 - val_loss: 0.4310 - val_accuracy: 0.8389\n",
      "Epoch 6/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.8863 - accuracy: 0.8570 - val_loss: 0.4266 - val_accuracy: 0.8547\n",
      "Epoch 7/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.8731 - accuracy: 0.8553 - val_loss: 0.4329 - val_accuracy: 0.8462\n",
      "Epoch 8/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.7440 - accuracy: 0.8645 - val_loss: 0.4351 - val_accuracy: 0.8530\n",
      "Epoch 9/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.7628 - accuracy: 0.8646 - val_loss: 0.4222 - val_accuracy: 0.8518\n",
      "Epoch 10/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.6508 - accuracy: 0.8709 - val_loss: 0.4219 - val_accuracy: 0.8491\n",
      "Epoch 11/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.5954 - accuracy: 0.8782 - val_loss: 0.4372 - val_accuracy: 0.8452\n",
      "Epoch 12/20\n",
      "992/992 [==============================] - 19s 19ms/step - loss: 1.5606 - accuracy: 0.8782 - val_loss: 0.4476 - val_accuracy: 0.8430\n",
      "Epoch 13/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.5213 - accuracy: 0.8823 - val_loss: 0.4124 - val_accuracy: 0.8535\n",
      "Epoch 14/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.4745 - accuracy: 0.8878 - val_loss: 0.4186 - val_accuracy: 0.8611\n",
      "Epoch 15/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.4595 - accuracy: 0.8875 - val_loss: 0.3931 - val_accuracy: 0.8643\n",
      "Epoch 16/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.4336 - accuracy: 0.8893 - val_loss: 0.4083 - val_accuracy: 0.8604\n",
      "Epoch 17/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.4174 - accuracy: 0.8921 - val_loss: 0.4224 - val_accuracy: 0.8550\n",
      "Epoch 18/20\n",
      "992/992 [==============================] - 18s 18ms/step - loss: 1.3653 - accuracy: 0.8938 - val_loss: 0.4261 - val_accuracy: 0.8542\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Fold 2: accuracy: 0.8642578125\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "999/999 [==============================] - 19s 18ms/step - loss: 4.7208 - accuracy: 0.6399 - val_loss: 0.6088 - val_accuracy: 0.7736\n",
      "Epoch 2/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 2.5290 - accuracy: 0.8055 - val_loss: 0.5003 - val_accuracy: 0.8203\n",
      "Epoch 3/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 2.1620 - accuracy: 0.8355 - val_loss: 0.4666 - val_accuracy: 0.8286\n",
      "Epoch 4/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 2.0176 - accuracy: 0.8443 - val_loss: 0.4537 - val_accuracy: 0.8326\n",
      "Epoch 5/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 1.9048 - accuracy: 0.8572 - val_loss: 0.5034 - val_accuracy: 0.8240\n",
      "Epoch 6/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 1.8082 - accuracy: 0.8631 - val_loss: 0.4736 - val_accuracy: 0.8306\n",
      "Epoch 7/20\n",
      "999/999 [==============================] - 18s 18ms/step - loss: 1.7503 - accuracy: 0.8686 - val_loss: 0.5197 - val_accuracy: 0.8193\n",
      "249/249 [==============================] - 3s 11ms/step\n",
      "Fold 3: accuracy: 0.8325803212851406\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1008/1008 [==============================] - 19s 18ms/step - loss: 4.7665 - accuracy: 0.6381 - val_loss: 0.5188 - val_accuracy: 0.7993\n",
      "Epoch 2/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 2.6491 - accuracy: 0.7974 - val_loss: 0.4119 - val_accuracy: 0.8413\n",
      "Epoch 3/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 2.2540 - accuracy: 0.8282 - val_loss: 0.4155 - val_accuracy: 0.8444\n",
      "Epoch 4/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 2.0740 - accuracy: 0.8437 - val_loss: 0.3773 - val_accuracy: 0.8519\n",
      "Epoch 5/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.9833 - accuracy: 0.8478 - val_loss: 0.3830 - val_accuracy: 0.8550\n",
      "Epoch 6/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.8739 - accuracy: 0.8573 - val_loss: 0.3967 - val_accuracy: 0.8530\n",
      "Epoch 7/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.7935 - accuracy: 0.8638 - val_loss: 0.3721 - val_accuracy: 0.8581\n",
      "Epoch 8/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.7193 - accuracy: 0.8715 - val_loss: 0.3692 - val_accuracy: 0.8633\n",
      "Epoch 9/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.6432 - accuracy: 0.8746 - val_loss: 0.3675 - val_accuracy: 0.8641\n",
      "Epoch 10/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.5701 - accuracy: 0.8792 - val_loss: 0.3857 - val_accuracy: 0.8576\n",
      "Epoch 11/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.5528 - accuracy: 0.8814 - val_loss: 0.3924 - val_accuracy: 0.8548\n",
      "Epoch 12/20\n",
      "1008/1008 [==============================] - 18s 18ms/step - loss: 1.4930 - accuracy: 0.8857 - val_loss: 0.3753 - val_accuracy: 0.8654\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8641078838174274\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "998/998 [==============================] - 19s 18ms/step - loss: 4.6964 - accuracy: 0.6465 - val_loss: 0.6375 - val_accuracy: 0.7648\n",
      "Epoch 2/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 2.5214 - accuracy: 0.8107 - val_loss: 0.5226 - val_accuracy: 0.8035\n",
      "Epoch 3/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 2.1618 - accuracy: 0.8366 - val_loss: 0.4696 - val_accuracy: 0.8198\n",
      "Epoch 4/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 2.0254 - accuracy: 0.8448 - val_loss: 0.4956 - val_accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.8611 - accuracy: 0.8575 - val_loss: 0.4853 - val_accuracy: 0.8213\n",
      "Epoch 6/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.7941 - accuracy: 0.8620 - val_loss: 0.4814 - val_accuracy: 0.8295\n",
      "Epoch 7/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.7372 - accuracy: 0.8682 - val_loss: 0.5260 - val_accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.6518 - accuracy: 0.8740 - val_loss: 0.4486 - val_accuracy: 0.8335\n",
      "Epoch 9/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.5592 - accuracy: 0.8768 - val_loss: 0.5561 - val_accuracy: 0.8037\n",
      "Epoch 10/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.5437 - accuracy: 0.8816 - val_loss: 0.4673 - val_accuracy: 0.8353\n",
      "Epoch 11/20\n",
      "998/998 [==============================] - 18s 18ms/step - loss: 1.4551 - accuracy: 0.8892 - val_loss: 0.4852 - val_accuracy: 0.8290\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.8335\n",
      "Average Accuracy: 0.8491581278233025\n",
      "Average F1-Score: 0.8501178701571064\n"
     ]
    }
   ],
   "source": [
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs={\"logs_path\": Path(\"logs/rnn_performance\"), \"additional_name\": \"GRU\"},\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1seq2seqGRU(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(\n",
    "    model, train_data, val_data, test_data, epochs=20, logs_path=Path(\"logs/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(\n",
    "    model,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    test_data,\n",
    "    epochs=20,\n",
    "    logs_path=Path(\"logs/\"),\n",
    "    generator=SequentialSAT1DataGenerator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run before re-training to clear up VRAM\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/gru/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/gru/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 154, 30)]         0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 154, 30)           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 154, 64)           18432     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 154, 32)           9408      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 154, 5)            165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28005 (109.39 KB)\n",
      "Trainable params: 28005 (109.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
