{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.pytorch.utilities import get_summary_str\n",
    "import xarray as xr\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from hmpai.data import CHANNELS_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/sat1/split_stage_data_100hz.nc\")\n",
    "data = xr.load_dataset(data_path)\n",
    "n_channels, n_samples, n_classes = (\n",
    "    len(data.channels),\n",
    "    len(data.samples),\n",
    "    len(data.labels),\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summ = lambda model, inp_size: summary(\n",
    "    model, input_size=inp_size, row_settings=[\"ascii_only\"], col_width=22\n",
    ")\n",
    "input_size = (batch_size, int(n_samples / 5), n_channels)\n",
    "input_size_deep = (batch_size, n_samples, n_channels)\n",
    "input_conv = (batch_size, n_samples, CHANNELS_2D.shape[1], CHANNELS_2D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "SAT1Base                                 [128, 5]               --\n",
      "+ PartialConv2d                          [128, 64, 155, 30]     384\n",
      "+ ReLU                                   [128, 64, 155, 30]     --\n",
      "+ MaxPool2d                              [128, 64, 77, 30]      --\n",
      "+ Conv2d                                 [128, 128, 75, 30]     24,704\n",
      "+ ReLU                                   [128, 128, 75, 30]     --\n",
      "+ MaxPool2d                              [128, 128, 37, 30]     --\n",
      "+ Conv2d                                 [128, 256, 35, 30]     98,560\n",
      "+ ReLU                                   [128, 256, 35, 30]     --\n",
      "+ MaxPool2d                              [128, 256, 17, 30]     --\n",
      "+ Flatten                                [128, 130560]          --\n",
      "+ Linear                                 [128, 128]             16,711,808\n",
      "+ ReLU                                   [128, 128]             --\n",
      "+ Dropout                                [128, 128]             --\n",
      "+ Linear                                 [128, 5]               645\n",
      "====================================================================================\n",
      "Total params: 16,836,101\n",
      "Trainable params: 16,836,101\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 22.73\n",
      "====================================================================================\n",
      "Input size (MB): 2.44\n",
      "Forward/backward pass size (MB): 875.04\n",
      "Params size (MB): 67.34\n",
      "Estimated Total Size (MB): 944.83\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SAT1Base(n_classes)\n",
    "print(get_summ(model, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "SAT1Topological                          [128, 5]               --\n",
      "+ PartialConv3d                          [128, 64, 795, 5, 8]   384\n",
      "+ ReLU                                   [128, 64, 795, 5, 8]   --\n",
      "+ MaxPool3d                              [128, 64, 397, 5, 8]   --\n",
      "+ Conv3d                                 [128, 128, 395, 5, 8]  24,704\n",
      "+ ReLU                                   [128, 128, 395, 5, 8]  --\n",
      "+ MaxPool3d                              [128, 128, 197, 5, 8]  --\n",
      "+ Conv3d                                 [128, 256, 195, 5, 8]  98,560\n",
      "+ ReLU                                   [128, 256, 195, 5, 8]  --\n",
      "+ MaxPool3d                              [128, 256, 97, 5, 8]   --\n",
      "+ Flatten                                [128, 993280]          --\n",
      "+ Linear                                 [128, 128]             127,139,968\n",
      "+ ReLU                                   [128, 128]             --\n",
      "+ Dropout                                [128, 128]             --\n",
      "+ Linear                                 [128, 5]               645\n",
      "====================================================================================\n",
      "Total params: 127,264,261\n",
      "Trainable params: 127,264,261\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 166.20\n",
      "====================================================================================\n",
      "Input size (MB): 16.36\n",
      "Forward/backward pass size (MB): 6199.84\n",
      "Params size (MB): 509.06\n",
      "Estimated Total Size (MB): 6725.26\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = SAT1Topological(n_classes)\n",
    "print(get_summ(model, input_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type)                             Output Shape              Param #\n",
      "==========================================================================================\n",
      "SAT1TopologicalConv                      [128, 5]                  --\n",
      "+ PartialConv3d                          [128, 64, 795, 3, 6]      2,944\n",
      "+ ReLU                                   [128, 64, 795, 3, 6]      --\n",
      "+ MaxPool3d                              [128, 64, 397, 3, 6]      --\n",
      "+ Conv3d                                 [128, 128, 395, 1, 4]     221,312\n",
      "+ ReLU                                   [128, 128, 395, 1, 4]     --\n",
      "+ MaxPool3d                              [128, 128, 197, 1, 4]     --\n",
      "+ Conv3d                                 [128, 256, 195, 1, 4]     98,560\n",
      "+ ReLU                                   [128, 256, 195, 1, 4]     --\n",
      "+ MaxPool3d                              [128, 256, 97, 1, 4]      --\n",
      "+ Flatten                                [128, 99328]              --\n",
      "+ Linear                                 [128, 128]                12,714,112\n",
      "+ ReLU                                   [128, 128]                --\n",
      "+ Dropout                                [128, 128]                --\n",
      "+ Linear                                 [128, 5]                  645\n",
      "==========================================================================================\n",
      "Total params: 13,037,573\n",
      "Trainable params: 13,037,573\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 61.62\n",
      "==========================================================================================\n",
      "Input size (MB): 16.36\n",
      "Forward/backward pass size (MB): 1349.52\n",
      "Params size (MB): 52.15\n",
      "Estimated Total Size (MB): 1418.04\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SAT1TopologicalConv(n_classes)\n",
    "print(get_summ(model, input_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "SAT1Deep                                 [128, 5]               --\n",
      "+ PartialConv2d                          [128, 32, 775, 30]     832\n",
      "+ ReLU                                   [128, 32, 775, 30]     --\n",
      "+ MaxPool2d                              [128, 32, 387, 30]     --\n",
      "+ Conv2d                                 [128, 64, 371, 30]     34,880\n",
      "+ ReLU                                   [128, 64, 371, 30]     --\n",
      "+ MaxPool2d                              [128, 64, 185, 30]     --\n",
      "+ Conv2d                                 [128, 128, 175, 30]    90,240\n",
      "+ ReLU                                   [128, 128, 175, 30]    --\n",
      "+ MaxPool2d                              [128, 128, 87, 30]     --\n",
      "+ Conv2d                                 [128, 256, 83, 30]     164,096\n",
      "+ ReLU                                   [128, 256, 83, 30]     --\n",
      "+ MaxPool2d                              [128, 256, 41, 30]     --\n",
      "+ Conv2d                                 [128, 512, 39, 30]     393,728\n",
      "+ ReLU                                   [128, 512, 39, 30]     --\n",
      "+ MaxPool2d                              [128, 512, 19, 30]     --\n",
      "+ Flatten                                [128, 291840]          --\n",
      "+ Linear                                 [128, 512]             149,422,592\n",
      "+ ReLU                                   [128, 512]             --\n",
      "+ Dropout                                [128, 512]             --\n",
      "+ Linear                                 [128, 5]               2,565\n",
      "====================================================================================\n",
      "Total params: 150,108,933\n",
      "Trainable params: 150,108,933\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 243.20\n",
      "====================================================================================\n",
      "Input size (MB): 12.27\n",
      "Forward/backward pass size (MB): 3446.08\n",
      "Params size (MB): 600.44\n",
      "Estimated Total Size (MB): 4058.79\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SAT1Deep(n_classes)\n",
    "print(get_summ(model, input_size_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "SAT1LSTM                                 [128, 5]               --\n",
      "+ LSTM                                   [102272, 256]          294,912\n",
      "+ ReLU                                   [128, 799, 256]        --\n",
      "+ Linear                                 [128, 799, 128]        32,896\n",
      "+ Linear                                 [128, 799, 5]          645\n",
      "====================================================================================\n",
      "Total params: 328,453\n",
      "Trainable params: 328,453\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.TERABYTES): 7.72\n",
      "====================================================================================\n",
      "Input size (MB): 12.27\n",
      "Forward/backward pass size (MB): 318.27\n",
      "Params size (MB): 1.31\n",
      "Estimated Total Size (MB): 331.86\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SAT1LSTM(n_channels, n_samples, n_classes)\n",
    "print(get_summ(model, input_size_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "SAT1GRU                                  [128, 5]               --\n",
      "+ GRU                                    [102272, 256]          221,184\n",
      "+ ReLU                                   [128, 799, 256]        --\n",
      "+ Linear                                 [128, 799, 128]        32,896\n",
      "+ Linear                                 [128, 799, 5]          645\n",
      "====================================================================================\n",
      "Total params: 254,725\n",
      "Trainable params: 254,725\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.TERABYTES): 5.79\n",
      "====================================================================================\n",
      "Input size (MB): 12.27\n",
      "Forward/backward pass size (MB): 318.27\n",
      "Params size (MB): 1.02\n",
      "Estimated Total Size (MB): 331.56\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SAT1GRU(n_channels, n_samples, n_classes)\n",
    "print(get_summ(model, input_size_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 161, 30])\n",
      "torch.float32\n",
      "====================================================================================\n",
      "Layer (type)                             Output Shape           Param #\n",
      "====================================================================================\n",
      "TransformerModel                         [128, 5]               --\n",
      "+ Linear                                 [128, 0, 30]           930\n",
      "+ PositionalEncoding                     [128, 0, 30]           --\n",
      "|    + Dropout                           [128, 0, 30]           --\n",
      "+ TransformerEncoder                     [128, 0, 30]           --\n",
      "|    + ModuleList                        --                     --\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "|    |    + TransformerEncoderLayer      [128, 0, 30]           35,102\n",
      "+ Linear                                 [128, 5]               155\n",
      "====================================================================================\n",
      "Total params: 211,697\n",
      "Trainable params: 211,697\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 24.24\n",
      "====================================================================================\n",
      "Input size (MB): 2.47\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.76\n",
      "Estimated Total Size (MB): 3.24\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(n_features=n_channels, n_heads=10, ff_dim=512, n_layers=6, n_samples=n_samples, n_classes=n_classes)\n",
    "# Remove masking before summary\n",
    "print(get_summ(model, input_size_deep))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
