{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hmpai.pytorch.utilities import *\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants\n",
    "from hmpai.normalization import *\n",
    "from hmpai.visualization import add_attribution\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from hmpai.data import preprocess\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "data_path = Path(\"../data/sat1/split_stage_data.nc\")\n",
    "dataset = xr.load_dataset(data_path)\n",
    "train_data, val_data, test_data = split_data_on_participants(dataset, 60, norm_dummy)\n",
    "chk_path = Path(\"../models/gru/checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load_model(chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAT1GRU(\n",
       "  (relu): ReLU()\n",
       "  (gru): GRU(30, 256, batch_first=True)\n",
       "  (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear_final): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    \"n_channels\": len(dataset.channels),\n",
    "    \"n_samples\": len(dataset.samples),\n",
    "    \"n_classes\": len(dataset.labels),\n",
    "}\n",
    "model = SAT1GRU(**model_kwargs)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1/125\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cudnn RNN backward can only be called in training mode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/visualization/captum.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/visualization/captum.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m attributions \u001b[39m=\u001b[39m add_attribution(test_data, ig)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/visualization/captum.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Fix data not on same device?\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/visualization.py:33\u001b[0m, in \u001b[0;36madd_attribution\u001b[0;34m(dataset, analyzer)\u001b[0m\n\u001b[1;32m     31\u001b[0m mask \u001b[39m=\u001b[39m baselines \u001b[39m!=\u001b[39m MASKING_VALUE\n\u001b[1;32m     32\u001b[0m baselines[mask] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 33\u001b[0m batch_analysis \u001b[39m=\u001b[39m analyzer\u001b[39m.\u001b[39;49mattribute(\n\u001b[1;32m     34\u001b[0m     batch_data,\n\u001b[1;32m     35\u001b[0m     baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m     36\u001b[0m     n_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mriemann_trapezoid\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     38\u001b[0m     target\u001b[39m=\u001b[39;49mbatch[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[1;32m     39\u001b[0m     internal_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m test_set\u001b[39m.\u001b[39manalysis[i \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39m1\u001b[39m]) : (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39m1\u001b[39m])] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(\n\u001b[1;32m     42\u001b[0m     batch_analysis\n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:274\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m internal_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     num_examples \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 274\u001b[0m     attributions \u001b[39m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[1;32m    277\u001b[0m         internal_batch_size,\n\u001b[1;32m    278\u001b[0m         n_steps,\n\u001b[1;32m    279\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    280\u001b[0m         baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m    281\u001b[0m         target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    282\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[1;32m    283\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[39m=\u001b[39mbaselines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/captum/attr/_utils/batching.py:78\u001b[0m, in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m step_sizes \u001b[39m=\u001b[39m full_step_sizes[start_step:end_step]\n\u001b[1;32m     77\u001b[0m alphas \u001b[39m=\u001b[39m full_alphas[start_step:end_step]\n\u001b[0;32m---> 78\u001b[0m current_attr \u001b[39m=\u001b[39m attr_method\u001b[39m.\u001b[39;49m_attribute(\n\u001b[1;32m     79\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, n_steps\u001b[39m=\u001b[39;49mbatch_steps, step_sizes_and_alphas\u001b[39m=\u001b[39;49m(step_sizes, alphas)\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m total_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     total_attr \u001b[39m=\u001b[39m current_attr\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[39m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[39m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[39m=\u001b[39;49mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[39m=\u001b[39;49mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[39m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(n_steps, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(step_sizes)\u001b[39m.\u001b[39mview(n_steps, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(grad\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[39mfor\u001b[39;00m grad \u001b[39min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/captum/_utils/gradient.py:119\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(torch\u001b[39m.\u001b[39;49munbind(outputs), inputs)\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m grads\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[39m=\u001b[39m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[39m=\u001b[39m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m         t_outputs,\n\u001b[1;32m    396\u001b[0m         grad_outputs_,\n\u001b[1;32m    397\u001b[0m         retain_graph,\n\u001b[1;32m    398\u001b[0m         create_graph,\n\u001b[1;32m    399\u001b[0m         t_inputs,\n\u001b[1;32m    400\u001b[0m         allow_unused,\n\u001b[1;32m    401\u001b[0m         accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    402\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mzeros_like(\u001b[39minput\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[39mfor\u001b[39;00m (output, \u001b[39minput\u001b[39m) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
     ]
    }
   ],
   "source": [
    "attributions = add_attribution(test_data, ig)\n",
    "# Fix data not on same device?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, _ = ig.attribute(\n",
    "    test_data,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
