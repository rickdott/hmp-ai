{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 13:07:27.035724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-28 13:07:27.620552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from shared.models import *\n",
    "from shared.generators import SAT1DataGenerator, NewSAT1DataGenerator\n",
    "from shared.utilities import *\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "random.seed(42)\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = data.participant.values.tolist()\n",
    "test_participants = random.sample(participants, 5)\n",
    "train_participants = [p for p in participants if p not in test_participants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.sel(participant=test_participants)\n",
    "train_data = data.sel(participant=train_participants)\n",
    "\n",
    "# train_data = data.sel(\n",
    "#     participant=[\n",
    "#         \"0021\",\n",
    "#         \"0022\",\n",
    "#         \"0023\",\n",
    "#         \"0024\",\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# test_data = data.sel(\n",
    "#     participant=[\n",
    "#         \"0025\"\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_gen = NewSAT1DataGenerator(train_data, batch_size=batch_size)\n",
    "test_gen = NewSAT1DataGenerator(test_data, batch_size=batch_size)\n",
    "\n",
    "# tf.config.optimizer.set_experimental_options({\"layout_optimizer\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 157, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 153, 64)       384       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 76, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 74, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 37, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 30, 35, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 17, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 130560)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16711808  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16835972 (64.22 MB)\n",
      "Trainable params: 16835972 (64.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 13:07:32.578206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:32.607275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:32.607376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:32.609674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:32.609766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:32.609838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:33.593667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:33.593744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:33.593752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-28 13:07:33.593797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-28 13:07:33.593947: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-08-28 13:07:33.593958: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-08-28 13:07:33.594388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21597 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = SAT1Base(30, 157, 4)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 13:07:39.621446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-28 13:07:41.096259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-28 13:07:41.104468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572e46f1230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-28 13:07:41.104495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-08-28 13:07:41.108113: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-28 13:07:41.214699: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 17s 15ms/step - loss: 1.3645 - accuracy: 0.2871 - val_loss: 1.3540 - val_accuracy: 0.2874\n",
      "Epoch 2/5\n",
      "785/785 [==============================] - 12s 14ms/step - loss: 1.3563 - accuracy: 0.3034 - val_loss: 1.3380 - val_accuracy: 0.2874\n",
      "Epoch 3/5\n",
      "785/785 [==============================] - 11s 14ms/step - loss: 1.2464 - accuracy: 0.4203 - val_loss: 1.0242 - val_accuracy: 0.5615\n",
      "Epoch 4/5\n",
      "785/785 [==============================] - 12s 14ms/step - loss: 1.0097 - accuracy: 0.5559 - val_loss: 0.8515 - val_accuracy: 0.6597\n",
      "Epoch 5/5\n",
      "785/785 [==============================] - 11s 14ms/step - loss: 0.9037 - accuracy: 0.6141 - val_loss: 0.7932 - val_accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "path = Path(\"logs/\") / run_id\n",
    "to_write = {\"Model summary\": get_summary_str(model), \"Test\": \"test:)\"}\n",
    "fit = model.fit(\n",
    "    train_gen,\n",
    "    epochs=5,\n",
    "    callbacks=[earlyStopping_cb, LoggingTensorBoard(to_write, log_dir=path)],\n",
    "    # TODO: Create val_gen\n",
    "    validation_data=test_gen,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run before re-training to clear up VRAM\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confirmation', 'decision', 'encoding', 'response']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen.cat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset results\n",
      "189/189 [==============================] - 2s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "confirmation       0.73      0.63      0.68       441\n",
      "    decision       0.72      0.81      0.76       844\n",
      "    encoding       0.88      0.89      0.89       869\n",
      "    response       0.84      0.80      0.82       870\n",
      "\n",
      "    accuracy                           0.80      3024\n",
      "   macro avg       0.80      0.78      0.79      3024\n",
      "weighted avg       0.81      0.80      0.80      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testset results\")\n",
    "predicted_classes = np.argmax(model.predict(test_gen), axis=1)\n",
    "predicted_classes = [test_gen.cat_labels[idx] for idx in list(predicted_classes)]\n",
    "print(classification_report(test_gen.full_labels, predicted_classes))\n",
    "# print(test_gen.categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
