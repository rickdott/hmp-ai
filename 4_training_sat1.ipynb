{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from shared.models import SAT1Start, ShallowConvNet, EEGNet\n",
    "from shared.generators import SAT1DataGenerator, NewSAT1DataGenerator\n",
    "from shared.utilities import earlyStopping_cb\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = data.participant.values.tolist()\n",
    "test_participants = random.sample(participants, 5)\n",
    "train_participants = [p for p in participants if p not in test_participants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.sel(participant=test_participants)\n",
    "train_data = data.sel(participant=train_participants)\n",
    "\n",
    "# train_data = data.sel(\n",
    "#     participant=[\n",
    "#         \"0021\",\n",
    "#         \"0022\",\n",
    "#         \"0023\",\n",
    "#         \"0024\",\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# test_data = data.sel(\n",
    "#     participant=[\n",
    "#         \"0025\"\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_gen = NewSAT1DataGenerator(train_data, batch_size=batch_size)\n",
    "test_gen = NewSAT1DataGenerator(test_data, batch_size=batch_size)\n",
    "\n",
    "# tf.config.optimizer.set_experimental_options({\"layout_optimizer\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run before re-training to clear up VRAM\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 157, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 153, 16)       96        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 153, 16)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 149, 32)       12832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 26, 149, 32)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 149, 64)       10304     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 22, 149, 64)       256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 22, 73, 64)        0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 73, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 102784)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 411140    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 434628 (1.66 MB)\n",
      "Trainable params: 434500 (1.66 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SAT1Start(30, 157, 4)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 13:04:00.993199: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 13s 15ms/step - loss: 1.3141 - accuracy: 0.4184 - val_loss: 1.3827 - val_accuracy: 0.4993\n",
      "Epoch 2/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.7947 - accuracy: 0.6740 - val_loss: 0.6465 - val_accuracy: 0.7389\n",
      "Epoch 3/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.6377 - accuracy: 0.7409 - val_loss: 1.4598 - val_accuracy: 0.6191\n",
      "Epoch 4/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.5801 - accuracy: 0.7677 - val_loss: 0.8980 - val_accuracy: 0.6584\n",
      "Epoch 5/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.5538 - accuracy: 0.7818 - val_loss: 2.0849 - val_accuracy: 0.5046\n",
      "Epoch 6/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.5350 - accuracy: 0.7863 - val_loss: 2.4800 - val_accuracy: 0.4810\n",
      "Epoch 7/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.5173 - accuracy: 0.7955 - val_loss: 2.3125 - val_accuracy: 0.4562\n",
      "Epoch 8/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.5075 - accuracy: 0.7999 - val_loss: 2.0525 - val_accuracy: 0.5049\n",
      "Epoch 9/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4917 - accuracy: 0.8081 - val_loss: 2.1720 - val_accuracy: 0.4634\n",
      "Epoch 10/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4783 - accuracy: 0.8167 - val_loss: 1.9008 - val_accuracy: 0.5141\n",
      "Epoch 11/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4643 - accuracy: 0.8174 - val_loss: 1.8981 - val_accuracy: 0.5213\n",
      "Epoch 12/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4514 - accuracy: 0.8218 - val_loss: 3.0048 - val_accuracy: 0.4463\n",
      "Epoch 13/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4463 - accuracy: 0.8286 - val_loss: 1.8698 - val_accuracy: 0.5514\n",
      "Epoch 14/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4351 - accuracy: 0.8344 - val_loss: 1.5908 - val_accuracy: 0.5550\n",
      "Epoch 15/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4317 - accuracy: 0.8325 - val_loss: 2.8889 - val_accuracy: 0.3992\n",
      "Epoch 16/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4138 - accuracy: 0.8398 - val_loss: 2.5669 - val_accuracy: 0.4584\n",
      "Epoch 17/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4153 - accuracy: 0.8384 - val_loss: 0.5457 - val_accuracy: 0.7830\n",
      "Epoch 18/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.4116 - accuracy: 0.8407 - val_loss: 1.0327 - val_accuracy: 0.6247\n",
      "Epoch 19/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.3963 - accuracy: 0.8486 - val_loss: 1.6177 - val_accuracy: 0.4997\n",
      "Epoch 20/20\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.3927 - accuracy: 0.8481 - val_loss: 2.1003 - val_accuracy: 0.4696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f22f460ab90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    # TODO: Create val_gen\n",
    "    validation_data=test_gen,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8,\n",
    ")\n",
    "\n",
    "# model.fit(\n",
    "#     train_gen,\n",
    "#     epochs=20,\n",
    "#     # TODO: Create val_gen (use 6th participant?)\n",
    "#     validation_data=test_gen,\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=8,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
