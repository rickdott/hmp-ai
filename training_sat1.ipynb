{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 11:58:03.745367: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 11:58:04.219757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from shared.models import SAT1Start, ShallowConvNet, EEGNet\n",
    "from shared.generators import SAT1DataGenerator\n",
    "from shared.utilities import earlyStopping_cb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'data21-25_AC.npz'\n",
    "data_path = Path('data/sat1') / data_name\n",
    "\n",
    "with np.load(data_path) as f_data:\n",
    "    data = f_data['data']\n",
    "    labels = f_data['labels']\n",
    "    participants = f_data['participants']\n",
    "    \n",
    "data = data.reshape(-1, 30, 210, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(list(set(labels.flatten())))\n",
    "x_train = data[np.isin(participants, ['0021', '0022', '0023', '0024'])]\n",
    "y_train = labels[np.isin(participants, ['0021', '0022', '0023', '0024'])]\n",
    "\n",
    "x_test = data[np.isin(participants, ['0025'])]\n",
    "y_test = labels[np.isin(participants, ['0025'])]\n",
    "\n",
    "train_gen = SAT1DataGenerator(x_train, y_train)\n",
    "test_gen = SAT1DataGenerator(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m----> 4\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m      5\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# # Run before re-training to clear up VRAM\n",
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 210, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 206, 16)       96        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 202, 32)       12832     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 202, 64)       10304     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 22, 202, 64)      256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 22, 99, 64)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 139392)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 557572    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 581,060\n",
      "Trainable params: 580,932\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 11:58:08.974220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:08.996513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:08.996582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:08.999018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:08.999071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:08.999110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:09.572441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:09.572507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:09.572515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-03 11:58:09.572558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-03 11:58:09.572568: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-07-03 11:58:09.572573: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-07-03 11:58:09.574433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5390 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model for 210 sample length, 30 electrodes/features, and 4 classes\n",
    "model = SAT1Start(30, 210, 4)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 11:58:11.607244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# model.fit(train_gen,\n",
    "#           epochs=20,\n",
    "#           # TODO: Create val_gen (use 6th participant?)\n",
    "#           validation_data=test_gen,\n",
    "#           callbacks=[earlyStopping_cb])\n",
    "model.fit(train_gen,\n",
    "          epochs=20,\n",
    "          # TODO: Create val_gen (use 6th participant?)\n",
    "          validation_data=test_gen,\n",
    "          batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset results\n",
      " 1/16 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 12:10:58.913476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.36      0.44        81\n",
      "           1       0.88      0.13      0.23        52\n",
      "           2       0.44      0.95      0.60        39\n",
      "           3       0.63      0.86      0.73        83\n",
      "\n",
      "    accuracy                           0.56       255\n",
      "   macro avg       0.63      0.57      0.50       255\n",
      "weighted avg       0.64      0.56      0.52       255\n",
      "\n",
      "['2', '3', 'motor', 'perception']\n"
     ]
    }
   ],
   "source": [
    "print('Testset results')\n",
    "predicted_classes = np.argmax(model.predict(test_gen), axis=1)\n",
    "print(classification_report(test_gen.labels_cat, predicted_classes))\n",
    "print(test_gen.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['motor', '3', '3', 'perception', 'perception', '3', 'perception',\n",
       "       'motor', '2', '3', '2', '3', 'perception', '2', 'perception', '2',\n",
       "       '2', 'motor', '3', 'perception', '2', 'motor', '2', '3', '2', '2',\n",
       "       'motor', '3', '3', 'perception', '2', 'motor', 'perception',\n",
       "       'perception', 'motor', '2', '2', '3', '3', '2', '3', '3', '2',\n",
       "       'perception', '2', '3', 'perception', 'perception', '2', 'motor',\n",
       "       'perception', '3', 'perception', 'motor', 'motor', 'perception',\n",
       "       '2', '2', '2', 'perception', 'perception', '2', '2', 'perception',\n",
       "       '2', '2', 'motor', '2', 'perception', '2', 'perception', '3', '2',\n",
       "       'perception', '3', 'perception', 'perception', '2', '3', '2', '3',\n",
       "       '2', '3', '2', 'perception', '2', 'perception', 'perception', '2',\n",
       "       'motor', 'perception', '3', 'motor', 'motor', 'perception',\n",
       "       'motor', 'perception', '3', 'motor', '3', 'perception', '3', '3',\n",
       "       '2', 'motor', '3', '2', '2', 'perception', 'motor', '2',\n",
       "       'perception', '2', '2', 'perception', '3', '2', 'perception', '2',\n",
       "       '2', 'perception', 'perception', '3', 'perception', '3', '3', '2',\n",
       "       '2', 'perception', 'perception', 'perception', 'perception', '2',\n",
       "       '3', '3', 'motor', 'perception', 'perception', 'motor', '2',\n",
       "       'perception', '2', 'perception', '3', '2', 'perception', '3', '2',\n",
       "       'perception', '3', 'perception', 'perception', 'motor',\n",
       "       'perception', 'perception', '2', '3', 'perception', 'perception',\n",
       "       'motor', 'motor', 'perception', 'perception', 'perception',\n",
       "       'motor', 'perception', 'motor', 'perception', '2', 'motor',\n",
       "       'motor', 'perception', '2', 'motor', 'perception', '2', '3',\n",
       "       'motor', 'perception', 'perception', '2', '2', 'motor', '3',\n",
       "       'motor', 'motor', 'perception', '2', 'perception', '3', '2',\n",
       "       'perception', '2', 'perception', '2', 'motor', '2', 'perception',\n",
       "       '2', '3', '3', '3', 'perception', '2', '3', 'motor', '3', '3', '3',\n",
       "       'perception', 'perception', '2', '3', '3', 'perception', 'motor',\n",
       "       '2', '3', 'motor', 'perception', 'perception', '2', '2',\n",
       "       'perception', '3', 'perception', 'perception', 'perception',\n",
       "       'perception', '2', 'motor', 'motor', '2', 'perception', '2', '2',\n",
       "       '2', 'perception', '2', 'motor', '3', '2', '2', '2', '2',\n",
       "       'perception', '2', 'perception', '2', '2', '2', '3', '2',\n",
       "       'perception', '2'], dtype='<U10')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen.labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
