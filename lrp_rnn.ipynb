{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:17:14.149959: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 15:17:14.727740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import innvestigate\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from shared.training import split_data_on_participants, train_and_evaluate\n",
    "from shared.normalization import *\n",
    "from shared.generators import SAT1DataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shared.data import SAT1_STAGES_ACCURACY\n",
    "from keras.models import load_model\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "from mne.viz import plot_topomap\n",
    "from mne.io import read_info\n",
    "from collections import defaultdict\n",
    "from shared.lstm_network import LSTM_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)\n",
    "\n",
    "train_data, val_data, test_data = split_data_on_participants(data, 60, norm_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = read_info(Path(\"data/sat1/preprocessed/processed_0001_epo.fif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "keras_model = load_model('models/sentiment_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:17:22.679979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:22.709455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:22.709529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:22.711716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:22.711785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:22.711828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:23.168196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:23.168280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:23.168288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-09 15:17:23.168335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-09 15:17:23.168360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-10-09 15:17:24.172505: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-10-09 15:17:24.178390: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/gru\")\n",
    "\n",
    "n_hidden = 256\n",
    "embedding_dim = 30\n",
    "n_classes = 5\n",
    "weights = model.get_weights()\n",
    "print(len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 768)\n",
      "(256, 768)\n",
      "(2, 768)\n",
      "(256, 128)\n",
      "(128,)\n",
      "(128, 5)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "for weight in weights:\n",
    "    print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/lrp_rnn.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/lrp_rnn.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m weights\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mzeros((n_classes,)))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/lrp_rnn.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m lrp_model \u001b[39m=\u001b[39m LSTM_network(n_hidden, embedding_dim, n_classes, weights\u001b[39m=\u001b[39;49mweights)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/shared/lstm_network.py:16\u001b[0m, in \u001b[0;36mLSTM_network.__init__\u001b[0;34m(self, n_hidden, embedding_dim, n_classes, weights, debug)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# model parameters\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_weights(weights)\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_x_fward \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(weights[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_h_fward \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(weights[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/shared/lstm_network.py:51\u001b[0m, in \u001b[0;36mLSTM_network.check_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_weights\u001b[39m(\u001b[39mself\u001b[39m, weights):\n\u001b[0;32m---> 51\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(weights) \u001b[39m==\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m     52\u001b[0m     \u001b[39massert\u001b[39;00m weights[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m weights[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dim, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_hidden)\n\u001b[1;32m     53\u001b[0m     \u001b[39massert\u001b[39;00m weights[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m weights[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_hidden, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_hidden)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights.append(np.zeros((n_classes,)))\n",
    "lrp_model = LSTM_network(n_hidden, embedding_dim, n_classes, weights=weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
