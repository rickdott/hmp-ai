{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import innvestigate\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from shared.training import split_data_on_participants, train_and_evaluate\n",
    "from shared.normalization import *\n",
    "from shared.generators import SAT1DataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shared.data import SAT1_STAGES_ACCURACY\n",
    "from keras.models import load_model\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "from mne.viz import plot_topomap\n",
    "from mne.io import read_info\n",
    "from collections import defaultdict\n",
    "from shared.lstm_network import LSTM_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "\n",
    "data = xr.load_dataset(data_path)\n",
    "\n",
    "train_data, val_data, test_data = split_data_on_participants(data, 60, norm_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = read_info(Path(\"data/sat1/preprocessed/processed_0001_epo.fif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "keras_model = load_model(\"models/sentiment_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 13:54:55.461462: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-10-23 13:54:55.560828: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-10-23 13:54:55.566637: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-10-23 13:54:56.122362: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/lstm\")\n",
    "\n",
    "n_hidden = 256\n",
    "embedding_dim = 30\n",
    "n_classes = 5\n",
    "weights = model.get_weights()\n",
    "# weights.insert(3, np.zeros_like(weights[0]))\n",
    "# weights.insert(4, np.zeros_like(weights[1]))\n",
    "# weights.insert(5, np.zeros_like(weights[2]))\n",
    "# weights[6] = np.append(weights[6], np.zeros_like(weights[6]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1024)\n",
      "(256, 1024)\n",
      "(1024,)\n",
      "(30, 1024)\n",
      "(256, 1024)\n",
      "(1024,)\n",
      "(512, 5)\n",
      "(5,)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for weight in weights:\n",
    "    print(weight.shape)\n",
    "print(len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_model = LSTM_network(n_hidden, embedding_dim, n_classes, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 147, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = SAT1DataGenerator(test_data)\n",
    "test_item = test_gen.__getitem__(0)\n",
    "test_item = test_item[0][0, :, :]\n",
    "test_item = np.expand_dims(test_item, 0)\n",
    "test_item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_item)\n",
    "print(np.argmax(predictions))\n",
    "lrp = lrp_model.full_pass(test_item)\n",
    "print(np.argmax(lrp[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float64, numpy=array([[-0.537052  ,  0.30001867, -1.45530712,  2.82691889, -2.29232346]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation, _ =  lrp_model.lrp(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 147, 30), dtype=float64, numpy=\n",
       "array([[[-1.91452425e+00, -4.02220065e-01, -1.65003839e-01, ...,\n",
       "          4.36453673e-01,  1.25822941e+00, -1.91818635e+00],\n",
       "        [-2.01447931e-01,  2.76592608e-03,  2.29935304e-01, ...,\n",
       "         -5.24956475e-02,  4.07994259e-01, -6.25517130e-01],\n",
       "        [-5.40137668e-03, -4.92411556e-02,  1.39664726e-01, ...,\n",
       "         -1.03041936e-01,  6.52144343e-02, -7.78840725e-02],\n",
       "        ...,\n",
       "        [ 3.19593875e-03,  5.64516740e-03, -3.07608029e-03, ...,\n",
       "         -2.92439637e-03, -4.95639715e-05,  1.67471654e-04],\n",
       "        [ 6.88304750e-03,  1.17758975e-02, -1.12168269e-02, ...,\n",
       "         -2.04791926e-02, -1.49691763e-02,  4.47918406e-03],\n",
       "        [ 1.98921186e+00, -3.88329332e-01,  3.01657218e+00, ...,\n",
       "         -8.72399564e-01,  1.11689727e-01, -2.96677539e-01]]])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argmax(lrp_model.full_pass(test_item)[0], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
