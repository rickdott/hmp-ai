{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Pre-processing and frequency sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is it possible to train a model on unpreprocessed EEG data and still attain similar performance levels?\n",
    "\n",
    "**Hypothesis**: The model will perform worse, but if still similar then the added value of not having to (manually) preprocess EEG data is very valuable and opens up a multitude of applications.\n",
    "\n",
    "**Result**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Preparing data\n",
    "To use hmp.utils.read_mne_data() and epoch the information, the files should be in .fif format, this replicates automated preprocessing as done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb excepting resampling to 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 11:47:27.610894: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 11:47:28.567013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import hsmm_mvpy as hmp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from shared.data import add_stage_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and file locations\n",
    "data_path = Path(\"/mnt/d/thesis/sat1/\")\n",
    "behavioral_data_path = data_path / \"ExperimentData/ExperimentData\"\n",
    "output_path = Path(\"data/sat1/unpreprocessed\")\n",
    "\n",
    "subj_ids = [\n",
    "    subj_id.name.split(\"-\")[1][:4] for subj_id in (data_path / \"eeg4\").glob(\"*.vhdr\")\n",
    "]\n",
    "subj_files = [\n",
    "    str(output_path / f\"unprocessed_{subj_id}_epo.fif\") for subj_id in subj_ids\n",
    "]\n",
    "behavioral_files = [\n",
    "    str(behavioral_data_path / f\"{subj_id}-cnv-sat3_ET.csv\") for subj_id in subj_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing preprocessing done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb\n",
    "# with only the necessary (non-manual) parts, like adding metadata for processing in HMP package, more info in link above\n",
    "for subject_id in subj_ids:\n",
    "    print(f\"Processing subject: {subject_id}\")\n",
    "    subject_id_short = subject_id.replace(\"0\", \"\")\n",
    "    raw = mne.io.read_raw_brainvision(\n",
    "        data_path / \"eeg4\" / f\"MD3-{subject_id}.vhdr\", preload=False\n",
    "    )\n",
    "    raw.set_channel_types(\n",
    "        {\"EOGh\": \"eog\", \"EOGv\": \"eog\", \"A1\": \"misc\", \"A2\": \"misc\"}\n",
    "    )  # Declare type to avoid confusion with EEG channels\n",
    "    raw.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    raw.set_montage(\"standard_1020\")  # Standard 10-20 electrode montage\n",
    "    raw.rename_channels({\"Fp1\": \"FP1\", \"Fp2\": \"FP2\"})\n",
    "\n",
    "    behavioral_path = behavioral_data_path / f\"{subject_id}-cnv-sat3_ET.csv\"\n",
    "    behavior = pd.read_csv(behavioral_path, sep=\";\")[\n",
    "        [\n",
    "            \"stim\",\n",
    "            \"resp\",\n",
    "            \"RT\",\n",
    "            \"cue\",\n",
    "            \"movement\",\n",
    "        ]\n",
    "    ]\n",
    "    behavior[\"movement\"] = behavior.apply(\n",
    "        lambda row: \"stim_left\"\n",
    "        if row[\"movement\"] == -1\n",
    "        else (\"stim_right\" if row[\"movement\"] == 1 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    behavior[\"resp\"] = behavior.apply(\n",
    "        lambda row: \"resp_left\"\n",
    "        if row[\"resp\"] == 1\n",
    "        else (\"resp_right\" if row[\"resp\"] == 2 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    # Merging together the exeperimental conditions info to have the format condition/stimulus/response\n",
    "    behavior[\"trigger\"] = (\n",
    "        behavior[\"cue\"] + \"/\" + behavior[\"movement\"] + \"/\" + behavior[\"resp\"]\n",
    "    )\n",
    "    # Filtering out < 300 and > 3000 Reaction times\n",
    "    behavior[\"RT\"] = behavior.apply(\n",
    "        lambda row: 0\n",
    "        if row[\"RT\"] < 300\n",
    "        else (0 if row[\"RT\"] > 3000 else float(row[\"RT\"]) / 1000),\n",
    "        axis=1,\n",
    "    )\n",
    "    epochs = mne.io.read_epochs_fieldtrip(\n",
    "        data_path / \"eeg1\" / f\"data{subject_id_short}.mat\", info=raw.info\n",
    "    )\n",
    "    epochs.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    epochs.set_montage(\"easycap-M1\")\n",
    "    epochs.filter(1, 35)  # Bandwidth filter from van Maanen, Portoles & Borst (2021)\n",
    "    epochs.crop(tmin=-0.250)\n",
    "    epochs.set_eeg_reference(\"average\")\n",
    "    epochs.metadata = behavior\n",
    "    epochs.save(\n",
    "        output_path / f\"unprocessed_{subject_id}_epo.fif\", overwrite=True, verbose=False\n",
    "    )  # Saving EEG mne format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_500hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_100hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    sfreq=100,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use information from stage_data to split unprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n",
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_500hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_100hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from shared.data import add_stage_dimension\n",
    "from shared.training import split_data_on_participants, train_and_evaluate, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.models import SAT1Base, SAT1Topological, SAT1Deep\n",
    "from shared.utilities import print_results\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = Path(\"logs/exp_preprocessing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a: Processed 100Hz (control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 17:46:44.898784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.931234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.931331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-17 17:46:45.414548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414559: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-17 17:46:45.414564: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-17 17:46:45.414675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 17:46:48.212527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-17 17:46:48.893596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-17 17:46:49.215032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556587cdee30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-17 17:46:49.215067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-17 17:46:49.221195: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 17:46:49.328577: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 17s 13ms/step - loss: 3.6975 - accuracy: 0.7287 - val_loss: 0.5757 - val_accuracy: 0.7936\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 13ms/step - loss: 2.8072 - accuracy: 0.7963 - val_loss: 0.5160 - val_accuracy: 0.8086\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.4092 - accuracy: 0.8225 - val_loss: 0.5079 - val_accuracy: 0.8093\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.1977 - accuracy: 0.8389 - val_loss: 0.4915 - val_accuracy: 0.8155\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.9734 - accuracy: 0.8527 - val_loss: 0.4765 - val_accuracy: 0.8204\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.8409 - accuracy: 0.8664 - val_loss: 0.4750 - val_accuracy: 0.8265\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6335 - accuracy: 0.8769 - val_loss: 0.5327 - val_accuracy: 0.8199\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.5267 - accuracy: 0.8880 - val_loss: 0.5130 - val_accuracy: 0.8216\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.3483 - accuracy: 0.8974 - val_loss: 0.5155 - val_accuracy: 0.8322\n",
      "254/254 [==============================] - 3s 10ms/step\n",
      "Fold 1: accuracy: 0.8265255905511811\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 3.8727 - accuracy: 0.7290 - val_loss: 0.5923 - val_accuracy: 0.7805\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.6737 - accuracy: 0.8013 - val_loss: 0.4755 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 14s 13ms/step - loss: 2.4567 - accuracy: 0.8184 - val_loss: 0.4463 - val_accuracy: 0.8323\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.2811 - accuracy: 0.8282 - val_loss: 0.4512 - val_accuracy: 0.8328\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.2080 - accuracy: 0.8352 - val_loss: 0.4537 - val_accuracy: 0.8352\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.0390 - accuracy: 0.8455 - val_loss: 0.4554 - val_accuracy: 0.8342\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.9194 - accuracy: 0.8571 - val_loss: 0.4463 - val_accuracy: 0.8394\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.8069 - accuracy: 0.8635 - val_loss: 0.4530 - val_accuracy: 0.8447\n",
      "Epoch 9/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.6828 - accuracy: 0.8735 - val_loss: 0.4679 - val_accuracy: 0.8418\n",
      "Epoch 10/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.5931 - accuracy: 0.8778 - val_loss: 0.4430 - val_accuracy: 0.8438\n",
      "Epoch 11/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.4559 - accuracy: 0.8869 - val_loss: 0.4841 - val_accuracy: 0.8491\n",
      "Epoch 12/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.3466 - accuracy: 0.8978 - val_loss: 0.5389 - val_accuracy: 0.8369\n",
      "Epoch 13/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.2917 - accuracy: 0.9004 - val_loss: 0.5121 - val_accuracy: 0.8411\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Fold 2: accuracy: 0.84375\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 4.1664 - accuracy: 0.6975 - val_loss: 0.5973 - val_accuracy: 0.7676\n",
      "Epoch 2/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 3.0478 - accuracy: 0.7765 - val_loss: 0.5512 - val_accuracy: 0.7846\n",
      "Epoch 3/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.6682 - accuracy: 0.8023 - val_loss: 0.5000 - val_accuracy: 0.8057\n",
      "Epoch 4/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.4336 - accuracy: 0.8223 - val_loss: 0.4922 - val_accuracy: 0.8085\n",
      "Epoch 5/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.2648 - accuracy: 0.8299 - val_loss: 0.4918 - val_accuracy: 0.8100\n",
      "Epoch 6/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.1633 - accuracy: 0.8381 - val_loss: 0.5074 - val_accuracy: 0.8095\n",
      "Epoch 7/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.0062 - accuracy: 0.8489 - val_loss: 0.5611 - val_accuracy: 0.7994\n",
      "Epoch 8/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.8843 - accuracy: 0.8552 - val_loss: 0.4908 - val_accuracy: 0.8175\n",
      "Epoch 9/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.8041 - accuracy: 0.8641 - val_loss: 0.5002 - val_accuracy: 0.8215\n",
      "Epoch 10/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.6816 - accuracy: 0.8718 - val_loss: 0.5391 - val_accuracy: 0.8090\n",
      "Epoch 11/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.5958 - accuracy: 0.8789 - val_loss: 0.5909 - val_accuracy: 0.8050\n",
      "249/249 [==============================] - 3s 11ms/step\n",
      "Fold 3: accuracy: 0.8175200803212851\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 3.9305 - accuracy: 0.7184 - val_loss: 0.5009 - val_accuracy: 0.8169\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.8161 - accuracy: 0.7941 - val_loss: 0.5508 - val_accuracy: 0.7884\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.5596 - accuracy: 0.8089 - val_loss: 0.4586 - val_accuracy: 0.8356\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.3705 - accuracy: 0.8216 - val_loss: 0.4426 - val_accuracy: 0.8452\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.2098 - accuracy: 0.8339 - val_loss: 0.4506 - val_accuracy: 0.8379\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.1070 - accuracy: 0.8444 - val_loss: 0.4402 - val_accuracy: 0.8444\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.9849 - accuracy: 0.8523 - val_loss: 0.4605 - val_accuracy: 0.8454\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.8860 - accuracy: 0.8570 - val_loss: 0.4502 - val_accuracy: 0.8511\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.7837 - accuracy: 0.8667 - val_loss: 0.4953 - val_accuracy: 0.8421\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8443983402489627\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 3.8962 - accuracy: 0.7237 - val_loss: 0.5502 - val_accuracy: 0.8023\n",
      "Epoch 2/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.7261 - accuracy: 0.7985 - val_loss: 0.4814 - val_accuracy: 0.8205\n",
      "Epoch 3/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.3934 - accuracy: 0.8212 - val_loss: 0.4476 - val_accuracy: 0.8317\n",
      "Epoch 4/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.1773 - accuracy: 0.8351 - val_loss: 0.4670 - val_accuracy: 0.8227\n",
      "Epoch 5/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.0778 - accuracy: 0.8463 - val_loss: 0.4515 - val_accuracy: 0.8270\n",
      "Epoch 6/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.8452 - accuracy: 0.8607 - val_loss: 0.4730 - val_accuracy: 0.8280\n",
      "Epoch 7/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.7761 - accuracy: 0.8648 - val_loss: 0.4662 - val_accuracy: 0.8278\n",
      "Epoch 8/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.6842 - accuracy: 0.8709 - val_loss: 0.4733 - val_accuracy: 0.8388\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.827\n",
      "Average Accuracy: 0.8318388022242857\n",
      "Average F1-Score: 0.8321140270388406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"default_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-default_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b: Unprocessed 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n",
      "997/997 [==============================] - 15s 14ms/step - loss: 3.4801 - accuracy: 0.7509 - val_loss: 0.5346 - val_accuracy: 0.8065\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.6244 - accuracy: 0.8129 - val_loss: 0.5000 - val_accuracy: 0.8252\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.3060 - accuracy: 0.8306 - val_loss: 0.4662 - val_accuracy: 0.8384\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.1392 - accuracy: 0.8437 - val_loss: 0.4516 - val_accuracy: 0.8431\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.9021 - accuracy: 0.8601 - val_loss: 0.4549 - val_accuracy: 0.8386\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.7453 - accuracy: 0.8738 - val_loss: 0.4557 - val_accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6421 - accuracy: 0.8776 - val_loss: 0.4490 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4681 - accuracy: 0.8887 - val_loss: 0.4692 - val_accuracy: 0.8484\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4217 - accuracy: 0.8989 - val_loss: 0.4579 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.2412 - accuracy: 0.9077 - val_loss: 0.4572 - val_accuracy: 0.8446\n",
      "251/251 [==============================] - 3s 10ms/step\n",
      "Fold 1: accuracy: 0.8533366533864541\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 3.9052 - accuracy: 0.7195 - val_loss: 0.6112 - val_accuracy: 0.7737\n",
      "Epoch 2/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.8202 - accuracy: 0.7913 - val_loss: 0.4972 - val_accuracy: 0.8225\n",
      "Epoch 3/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.4260 - accuracy: 0.8187 - val_loss: 0.4926 - val_accuracy: 0.8210\n",
      "Epoch 4/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.2892 - accuracy: 0.8258 - val_loss: 0.4808 - val_accuracy: 0.8271\n",
      "Epoch 5/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.0932 - accuracy: 0.8419 - val_loss: 0.4423 - val_accuracy: 0.8452\n",
      "Epoch 6/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.9960 - accuracy: 0.8514 - val_loss: 0.4419 - val_accuracy: 0.8459\n",
      "Epoch 7/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.8740 - accuracy: 0.8587 - val_loss: 0.4538 - val_accuracy: 0.8406\n",
      "Epoch 8/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.8103 - accuracy: 0.8638 - val_loss: 0.4482 - val_accuracy: 0.8501\n",
      "Epoch 9/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.5907 - accuracy: 0.8773 - val_loss: 0.4390 - val_accuracy: 0.8535\n",
      "Epoch 10/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.5033 - accuracy: 0.8858 - val_loss: 0.4365 - val_accuracy: 0.8577\n",
      "Epoch 11/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.4056 - accuracy: 0.8911 - val_loss: 0.4541 - val_accuracy: 0.8547\n",
      "Epoch 12/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.2970 - accuracy: 0.9003 - val_loss: 0.4965 - val_accuracy: 0.8542\n",
      "Epoch 13/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.2895 - accuracy: 0.9042 - val_loss: 0.5028 - val_accuracy: 0.8518\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Fold 2: accuracy: 0.857666015625\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 3.5474 - accuracy: 0.7528 - val_loss: 0.5517 - val_accuracy: 0.7999\n",
      "Epoch 2/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.6378 - accuracy: 0.8112 - val_loss: 0.5351 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.3160 - accuracy: 0.8311 - val_loss: 0.4999 - val_accuracy: 0.8173\n",
      "Epoch 4/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.1267 - accuracy: 0.8435 - val_loss: 0.4660 - val_accuracy: 0.8361\n",
      "Epoch 5/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.0084 - accuracy: 0.8505 - val_loss: 0.4922 - val_accuracy: 0.8198\n",
      "Epoch 6/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.8611 - accuracy: 0.8631 - val_loss: 0.4985 - val_accuracy: 0.8233\n",
      "Epoch 7/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.7578 - accuracy: 0.8693 - val_loss: 0.4891 - val_accuracy: 0.8296\n",
      "249/249 [==============================] - 3s 11ms/step\n",
      "Fold 3: accuracy: 0.8360943775100401\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 3.7614 - accuracy: 0.7405 - val_loss: 0.4651 - val_accuracy: 0.8327\n",
      "Epoch 2/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.6389 - accuracy: 0.8047 - val_loss: 0.5074 - val_accuracy: 0.8195\n",
      "Epoch 3/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.4270 - accuracy: 0.8218 - val_loss: 0.4696 - val_accuracy: 0.8332\n",
      "Epoch 4/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.2047 - accuracy: 0.8359 - val_loss: 0.4226 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.0879 - accuracy: 0.8447 - val_loss: 0.4064 - val_accuracy: 0.8527\n",
      "Epoch 6/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.0028 - accuracy: 0.8467 - val_loss: 0.4153 - val_accuracy: 0.8576\n",
      "Epoch 7/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.8328 - accuracy: 0.8609 - val_loss: 0.4278 - val_accuracy: 0.8641\n",
      "Epoch 8/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.7824 - accuracy: 0.8643 - val_loss: 0.4638 - val_accuracy: 0.8426\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8526970954356846\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 3.4941 - accuracy: 0.7578 - val_loss: 0.5525 - val_accuracy: 0.7937\n",
      "Epoch 2/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.5227 - accuracy: 0.8165 - val_loss: 0.5137 - val_accuracy: 0.8117\n",
      "Epoch 3/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.2106 - accuracy: 0.8349 - val_loss: 0.4971 - val_accuracy: 0.8167\n",
      "Epoch 4/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.0230 - accuracy: 0.8526 - val_loss: 0.4871 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.8643 - accuracy: 0.8618 - val_loss: 0.5087 - val_accuracy: 0.8207\n",
      "975/998 [============================>.] - ETA: 0s - loss: 1.8593 - accuracy: 0.8617Epoch 6/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.7266 - accuracy: 0.8719 - val_loss: 0.5067 - val_accuracy: 0.8213\n",
      "Epoch 7/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.5975 - accuracy: 0.8813 - val_loss: 0.5027 - val_accuracy: 0.8310\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.8255\n",
      "Average Accuracy: 0.8450588283914359\n",
      "Average F1-Score: 0.8452467751439409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38733"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2c: Unprocessed 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 19:18:19.950255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 19:18:20.998533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from shared.data import add_stage_dimension, preprocess\n",
    "from shared.training import split_data_on_participants, train_and_evaluate, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.models import SAT1Base, SAT1Topological, SAT1Deep\n",
    "from shared.utilities import print_results\n",
    "import gc\n",
    "import numpy as np\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "data = xr.load_dataset(data_path)\n",
    "logs_path = Path(\"logs/exp_preprocessing/\")\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_500hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_500hz\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 18:43:12.693239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:12.715023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:12.715103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:12.716736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:12.716810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:12.716862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:13.267627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:13.267719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:13.267728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-21 18:43:13.267782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:43:13.267792: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-21 18:43:13.267798: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-21 18:43:13.267905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 18:43:20.365859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-21 18:43:21.683663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-21 18:43:23.038706: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb47203b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-21 18:43:23.038743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-21 18:43:23.045466: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-21 18:43:23.159978: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993/993 [==============================] - 63s 57ms/step - loss: 3.2354 - accuracy: 0.7752 - val_loss: 0.5002 - val_accuracy: 0.7945\n",
      "Epoch 2/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.5197 - accuracy: 0.8138 - val_loss: 0.5243 - val_accuracy: 0.7970\n",
      "Epoch 3/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.2262 - accuracy: 0.8316 - val_loss: 0.4594 - val_accuracy: 0.8087\n",
      "Epoch 4/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 2.1014 - accuracy: 0.8376 - val_loss: 0.4460 - val_accuracy: 0.8115\n",
      "Epoch 5/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.9335 - accuracy: 0.8504 - val_loss: 0.4389 - val_accuracy: 0.8248\n",
      "Epoch 6/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.8079 - accuracy: 0.8586 - val_loss: 0.4245 - val_accuracy: 0.8195\n",
      "Epoch 7/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.6791 - accuracy: 0.8718 - val_loss: 0.4536 - val_accuracy: 0.8315\n",
      "Epoch 8/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.5532 - accuracy: 0.8805 - val_loss: 0.3895 - val_accuracy: 0.8487\n",
      "Epoch 9/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.4143 - accuracy: 0.8922 - val_loss: 0.4518 - val_accuracy: 0.8350\n",
      "Epoch 10/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.2554 - accuracy: 0.9039 - val_loss: 0.4384 - val_accuracy: 0.8425\n",
      "Epoch 11/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 1.1121 - accuracy: 0.9131 - val_loss: 0.4967 - val_accuracy: 0.8342\n",
      "250/250 [==============================] - 3s 13ms/step\n",
      "Fold 1: Accuracy: 0.84875\n",
      "Fold 1: F1-Score: 0.8299710480663565\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "988/988 [==============================] - 58s 56ms/step - loss: 3.2411 - accuracy: 0.7707 - val_loss: 0.4651 - val_accuracy: 0.8074\n",
      "Epoch 2/20\n",
      "988/988 [==============================] - 56s 56ms/step - loss: 2.5220 - accuracy: 0.8134 - val_loss: 0.4641 - val_accuracy: 0.8164\n",
      "Epoch 3/20\n",
      "988/988 [==============================] - 56s 56ms/step - loss: 2.3753 - accuracy: 0.8220 - val_loss: 0.4792 - val_accuracy: 0.8044\n",
      "Epoch 4/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 2.1586 - accuracy: 0.8336 - val_loss: 0.4636 - val_accuracy: 0.8056\n",
      "Epoch 5/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 2.0021 - accuracy: 0.8462 - val_loss: 0.3984 - val_accuracy: 0.8475\n",
      "Epoch 6/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 1.8085 - accuracy: 0.8623 - val_loss: 0.3867 - val_accuracy: 0.8471\n",
      "Epoch 7/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 1.6799 - accuracy: 0.8725 - val_loss: 0.3673 - val_accuracy: 0.8600\n",
      "Epoch 8/20\n",
      "988/988 [==============================] - 56s 56ms/step - loss: 1.5875 - accuracy: 0.8813 - val_loss: 0.3852 - val_accuracy: 0.8556\n",
      "Epoch 9/20\n",
      "988/988 [==============================] - 56s 56ms/step - loss: 1.3634 - accuracy: 0.8957 - val_loss: 0.4121 - val_accuracy: 0.8468\n",
      "Epoch 10/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 1.2623 - accuracy: 0.9068 - val_loss: 0.3636 - val_accuracy: 0.8654\n",
      "Epoch 11/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 1.1100 - accuracy: 0.9207 - val_loss: 0.4217 - val_accuracy: 0.8713\n",
      "Epoch 12/20\n",
      "988/988 [==============================] - 56s 56ms/step - loss: 0.9100 - accuracy: 0.9315 - val_loss: 0.4345 - val_accuracy: 0.8637\n",
      "Epoch 13/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 0.8209 - accuracy: 0.9402 - val_loss: 0.4586 - val_accuracy: 0.8721\n",
      "255/255 [==============================] - 3s 13ms/step\n",
      "Fold 2: Accuracy: 0.8654411764705883\n",
      "Fold 2: F1-Score: 0.8494032250760399\n",
      "Fold accuracy: 0.84875\n",
      "Fold accuracy: 0.8654411764705883\n",
      "Average Accuracy: 0.8570955882352942\n",
      "Average F1-Score: 0.8396871365711982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3336"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[0, 1],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 19:18:32.071445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.129165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.129407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.132035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.132164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.132258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.797156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.797249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.797258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-21 19:18:32.797315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 19:18:32.797327: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-21 19:18:32.797333: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-21 19:18:32.797447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 19:18:39.829011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-21 19:18:41.180223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-21 19:18:42.509853: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f70fa8ce7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-21 19:18:42.509893: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-21 19:18:42.516786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-21 19:18:42.640684: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 62s 56ms/step - loss: 3.1774 - accuracy: 0.7686 - val_loss: 0.4973 - val_accuracy: 0.8208\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 56s 55ms/step - loss: 2.5422 - accuracy: 0.8126 - val_loss: 0.4567 - val_accuracy: 0.8236\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 2.1661 - accuracy: 0.8374 - val_loss: 0.3858 - val_accuracy: 0.8443\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 57s 56ms/step - loss: 2.0403 - accuracy: 0.8465 - val_loss: 0.3932 - val_accuracy: 0.8498\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.7906 - accuracy: 0.8623 - val_loss: 0.3388 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.5996 - accuracy: 0.8822 - val_loss: 0.3257 - val_accuracy: 0.8868\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.3620 - accuracy: 0.9033 - val_loss: 0.3433 - val_accuracy: 0.8873\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.1831 - accuracy: 0.9169 - val_loss: 0.3602 - val_accuracy: 0.8863\n",
      "Epoch 9/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.0980 - accuracy: 0.9227 - val_loss: 0.3188 - val_accuracy: 0.9007\n",
      "Epoch 10/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 0.9061 - accuracy: 0.9361 - val_loss: 0.3131 - val_accuracy: 0.9098\n",
      "Epoch 11/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 0.7643 - accuracy: 0.9439 - val_loss: 0.4405 - val_accuracy: 0.8952\n",
      "Epoch 12/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 0.7583 - accuracy: 0.9489 - val_loss: 0.3693 - val_accuracy: 0.8984\n",
      "Epoch 13/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 0.5767 - accuracy: 0.9606 - val_loss: 0.3820 - val_accuracy: 0.9027\n",
      "248/248 [==============================] - 4s 14ms/step\n",
      "Fold 3: Accuracy: 0.9097782258064516\n",
      "Fold 3: F1-Score: 0.9022118713669152\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1004/1004 [==============================] - 60s 57ms/step - loss: 3.3312 - accuracy: 0.7623 - val_loss: 0.4896 - val_accuracy: 0.8138\n",
      "Epoch 2/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 2.5736 - accuracy: 0.8051 - val_loss: 0.4071 - val_accuracy: 0.8439\n",
      "Epoch 3/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.3388 - accuracy: 0.8186 - val_loss: 0.3997 - val_accuracy: 0.8423\n",
      "Epoch 4/20\n",
      "1004/1004 [==============================] - 58s 58ms/step - loss: 2.1318 - accuracy: 0.8369 - val_loss: 0.3772 - val_accuracy: 0.8512\n",
      "Epoch 5/20\n",
      "  19/1004 [..............................] - ETA: 49s - loss: 2.0594 - accuracy: 0.8553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/exp_preprocessing.ipynb Cell 29\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m SAT1Deep(\u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mchannels), \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39msamples), \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mlabels))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m k_fold_cross_validate(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     data,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     model,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     normalization_fn\u001b[39m=\u001b[39;49mnorm_dummy,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     train_kwargs\u001b[39m=\u001b[39;49mtrain_kwargs,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     fold_indices\u001b[39m=\u001b[39;49m[\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m print_results(results)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/exp_preprocessing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/shared/training.py:275\u001b[0m, in \u001b[0;36mk_fold_cross_validate\u001b[0;34m(data, model, k, batch_size, epochs, workers, normalization_fn, gen_kwargs, train_kwargs, fold_indices)\u001b[0m\n\u001b[1;32m    273\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mget_compile_kwargs())\n\u001b[1;32m    274\u001b[0m \u001b[39m# Train model and test\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m result \u001b[39m=\u001b[39m train_and_evaluate(\n\u001b[1;32m    276\u001b[0m     model,\n\u001b[1;32m    277\u001b[0m     train_data,\n\u001b[1;32m    278\u001b[0m     test_data,\n\u001b[1;32m    279\u001b[0m     val\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m    280\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    281\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    282\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    283\u001b[0m     gen_kwargs\u001b[39m=\u001b[39;49mgen_kwargs,\n\u001b[1;32m    284\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_kwargs,\n\u001b[1;32m    285\u001b[0m )[\u001b[39m1\u001b[39m]\n\u001b[1;32m    286\u001b[0m \u001b[39m# Add test results to list\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/shared/training.py:159\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train, test, val, batch_size, epochs, workers, logs_path, additional_info, additional_name, generator, gen_kwargs, use_class_weights)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m use_class_weights:\n\u001b[1;32m    158\u001b[0m     fit_args[\u001b[39m\"\u001b[39m\u001b[39mclass_weight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m calculate_class_weights(train_gen)\n\u001b[0;32m--> 159\u001b[0m fit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    160\u001b[0m     train_gen,\n\u001b[1;32m    161\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    162\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    163\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_gen,\n\u001b[1;32m    164\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m    165\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    166\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m \u001b[39m# Test model and write test summary\u001b[39;00m\n\u001b[1;32m    170\u001b[0m test_args \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[2, 3],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 18:15:49.743225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:49.764235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:49.764324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:49.766144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:49.766217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:49.766270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:50.313565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:50.313658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:50.313667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-21 18:15:50.313724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 18:15:50.313734: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-21 18:15:50.313739: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-21 18:15:50.313841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 18:15:57.337846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-21 18:15:58.610640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-21 18:15:59.949284: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f09e8754f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-21 18:15:59.949326: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-21 18:15:59.956073: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-21 18:16:00.071915: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 [==============================] - 62s 56ms/step - loss: 3.1172 - accuracy: 0.7764 - val_loss: 0.5283 - val_accuracy: 0.8105\n",
      "Epoch 2/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 2.3891 - accuracy: 0.8203 - val_loss: 0.4704 - val_accuracy: 0.8253\n",
      "Epoch 3/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 2.1422 - accuracy: 0.8382 - val_loss: 0.4173 - val_accuracy: 0.8384\n",
      "Epoch 4/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.9751 - accuracy: 0.8504 - val_loss: 0.4701 - val_accuracy: 0.8165\n",
      "Epoch 5/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 1.9207 - accuracy: 0.8580 - val_loss: 0.4258 - val_accuracy: 0.8316\n",
      "Epoch 6/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 1.7786 - accuracy: 0.8631 - val_loss: 0.4263 - val_accuracy: 0.8358\n",
      "Epoch 7/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 1.5908 - accuracy: 0.8788 - val_loss: 0.4187 - val_accuracy: 0.8444\n",
      "Epoch 8/20\n",
      "994/994 [==============================] - 58s 58ms/step - loss: 1.4929 - accuracy: 0.8877 - val_loss: 0.4667 - val_accuracy: 0.8411\n",
      "Epoch 9/20\n",
      "994/994 [==============================] - 58s 58ms/step - loss: 1.3488 - accuracy: 0.8981 - val_loss: 0.5033 - val_accuracy: 0.8419\n",
      "Epoch 10/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.2348 - accuracy: 0.9057 - val_loss: 0.4494 - val_accuracy: 0.8451\n",
      "249/249 [==============================] - 3s 13ms/step\n",
      "Fold 5: accuracy: 0.8443775100401606\n",
      "Fold accuracy: 0.8443775100401606\n",
      "Average Accuracy: 0.8443775100401606\n",
      "Average F1-Score: 0.823221589444174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[4],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622609537903108\n"
     ]
    }
   ],
   "source": [
    "avgs = [0.871, 0.8475490196078431, 0.8694556451612904, 0.8789225941422594, 0.8443775100401606]\n",
    "print(np.mean(avgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deprecated due to memory leak issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "# model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_500hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_500hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:59:04.226414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# View results in Tensorboard\n",
    "! tensorboard --logdir logs/exp_preprocessing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
