{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Pre-processing and frequency sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is it possible to train a model on unpreprocessed EEG data and still attain similar performance levels?\n",
    "\n",
    "**Hypothesis**: The model will perform worse, but if still similar then the added value of not having to (manually) preprocess EEG data is very valuable and opens up a multitude of applications.\n",
    "\n",
    "**Result**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Preparing data\n",
    "To use hmp.utils.read_mne_data() and epoch the information, the files should be in .fif format, this replicates automated preprocessing as done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb excepting resampling to 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 11:47:27.610894: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 11:47:28.567013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import hsmm_mvpy as hmp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from shared.data import add_stage_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and file locations\n",
    "data_path = Path(\"/mnt/d/thesis/sat1/\")\n",
    "behavioral_data_path = data_path / \"ExperimentData/ExperimentData\"\n",
    "output_path = Path(\"data/sat1/unpreprocessed\")\n",
    "\n",
    "subj_ids = [\n",
    "    subj_id.name.split(\"-\")[1][:4] for subj_id in (data_path / \"eeg4\").glob(\"*.vhdr\")\n",
    "]\n",
    "subj_files = [\n",
    "    str(output_path / f\"unprocessed_{subj_id}_epo.fif\") for subj_id in subj_ids\n",
    "]\n",
    "behavioral_files = [\n",
    "    str(behavioral_data_path / f\"{subj_id}-cnv-sat3_ET.csv\") for subj_id in subj_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing preprocessing done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb\n",
    "# with only the necessary (non-manual) parts, like adding metadata for processing in HMP package, more info in link above\n",
    "for subject_id in subj_ids:\n",
    "    print(f\"Processing subject: {subject_id}\")\n",
    "    subject_id_short = subject_id.replace(\"0\", \"\")\n",
    "    raw = mne.io.read_raw_brainvision(\n",
    "        data_path / \"eeg4\" / f\"MD3-{subject_id}.vhdr\", preload=False\n",
    "    )\n",
    "    raw.set_channel_types(\n",
    "        {\"EOGh\": \"eog\", \"EOGv\": \"eog\", \"A1\": \"misc\", \"A2\": \"misc\"}\n",
    "    )  # Declare type to avoid confusion with EEG channels\n",
    "    raw.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    raw.set_montage(\"standard_1020\")  # Standard 10-20 electrode montage\n",
    "    raw.rename_channels({\"Fp1\": \"FP1\", \"Fp2\": \"FP2\"})\n",
    "\n",
    "    behavioral_path = behavioral_data_path / f\"{subject_id}-cnv-sat3_ET.csv\"\n",
    "    behavior = pd.read_csv(behavioral_path, sep=\";\")[\n",
    "        [\n",
    "            \"stim\",\n",
    "            \"resp\",\n",
    "            \"RT\",\n",
    "            \"cue\",\n",
    "            \"movement\",\n",
    "        ]\n",
    "    ]\n",
    "    behavior[\"movement\"] = behavior.apply(\n",
    "        lambda row: \"stim_left\"\n",
    "        if row[\"movement\"] == -1\n",
    "        else (\"stim_right\" if row[\"movement\"] == 1 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    behavior[\"resp\"] = behavior.apply(\n",
    "        lambda row: \"resp_left\"\n",
    "        if row[\"resp\"] == 1\n",
    "        else (\"resp_right\" if row[\"resp\"] == 2 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    # Merging together the exeperimental conditions info to have the format condition/stimulus/response\n",
    "    behavior[\"trigger\"] = (\n",
    "        behavior[\"cue\"] + \"/\" + behavior[\"movement\"] + \"/\" + behavior[\"resp\"]\n",
    "    )\n",
    "    # Filtering out < 300 and > 3000 Reaction times\n",
    "    behavior[\"RT\"] = behavior.apply(\n",
    "        lambda row: 0\n",
    "        if row[\"RT\"] < 300\n",
    "        else (0 if row[\"RT\"] > 3000 else float(row[\"RT\"]) / 1000),\n",
    "        axis=1,\n",
    "    )\n",
    "    epochs = mne.io.read_epochs_fieldtrip(\n",
    "        data_path / \"eeg1\" / f\"data{subject_id_short}.mat\", info=raw.info\n",
    "    )\n",
    "    epochs.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    epochs.set_montage(\"easycap-M1\")\n",
    "    epochs.filter(1, 35)  # Bandwidth filter from van Maanen, Portoles & Borst (2021)\n",
    "    epochs.crop(tmin=-0.250)\n",
    "    epochs.set_eeg_reference(\"average\")\n",
    "    epochs.metadata = behavior\n",
    "    epochs.save(\n",
    "        output_path / f\"unprocessed_{subject_id}_epo.fif\", overwrite=True, verbose=False\n",
    "    )  # Saving EEG mne format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_500hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_100hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    sfreq=100,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use information from stage_data to split unprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n",
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_500hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_100hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:42:41.782883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-22 12:42:42.827944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from shared.data import add_stage_dimension\n",
    "from shared.training import split_data_on_participants, train_and_evaluate, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.models import SAT1Base, SAT1Topological, SAT1Deep\n",
    "from shared.utilities import print_results\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = Path(\"logs/exp_preprocessing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a: Processed 100Hz (control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 11:52:16.341668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.370608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.370695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.373135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.373196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.373239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.888690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.888787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.888797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 11:52:16.888848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 11:52:16.888860: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-22 11:52:16.888865: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-22 11:52:16.888972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 11:52:19.943660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-22 11:52:20.724324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-22 11:52:21.079425: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f76cae28870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-22 11:52:21.079465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-22 11:52:21.086161: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-22 11:52:21.194820: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 18s 14ms/step - loss: 3.7138 - accuracy: 0.7257 - val_loss: 0.5702 - val_accuracy: 0.7970\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.7412 - accuracy: 0.8044 - val_loss: 0.5133 - val_accuracy: 0.8091\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 13s 13ms/step - loss: 2.4400 - accuracy: 0.8225 - val_loss: 0.4843 - val_accuracy: 0.8204\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.1581 - accuracy: 0.8446 - val_loss: 0.4814 - val_accuracy: 0.8211\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.9349 - accuracy: 0.8573 - val_loss: 0.4780 - val_accuracy: 0.8228\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.8074 - accuracy: 0.8688 - val_loss: 0.4544 - val_accuracy: 0.8351\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6332 - accuracy: 0.8801 - val_loss: 0.4791 - val_accuracy: 0.8285\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4944 - accuracy: 0.8887 - val_loss: 0.4939 - val_accuracy: 0.8282\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.3889 - accuracy: 0.8981 - val_loss: 0.5274 - val_accuracy: 0.8243\n",
      "254/254 [==============================] - 3s 10ms/step\n",
      "Fold 1: Accuracy: 0.8353838582677166\n",
      "Fold 1: F1-Score: 0.8330978666130642\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "995/995 [==============================] - 16s 14ms/step - loss: 3.7720 - accuracy: 0.7269 - val_loss: 0.5474 - val_accuracy: 0.7991\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.8161 - accuracy: 0.7938 - val_loss: 0.5160 - val_accuracy: 0.8115\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.4747 - accuracy: 0.8198 - val_loss: 0.4609 - val_accuracy: 0.8274\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.2458 - accuracy: 0.8355 - val_loss: 0.4496 - val_accuracy: 0.8362\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.0758 - accuracy: 0.8465 - val_loss: 0.4477 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.8922 - accuracy: 0.8590 - val_loss: 0.4642 - val_accuracy: 0.8384\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.7277 - accuracy: 0.8700 - val_loss: 0.5241 - val_accuracy: 0.8372\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.6480 - accuracy: 0.8789 - val_loss: 0.4757 - val_accuracy: 0.8472\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Fold 2: Accuracy: 0.84375\n",
      "Fold 2: F1-Score: 0.8436405304267435\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "1002/1002 [==============================] - 16s 14ms/step - loss: 3.6680 - accuracy: 0.7320 - val_loss: 0.5494 - val_accuracy: 0.7904\n",
      "Epoch 2/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.7721 - accuracy: 0.8029 - val_loss: 0.5500 - val_accuracy: 0.7942\n",
      "Epoch 3/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.4133 - accuracy: 0.8247 - val_loss: 0.5077 - val_accuracy: 0.8135\n",
      "Epoch 4/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.1110 - accuracy: 0.8426 - val_loss: 0.5231 - val_accuracy: 0.8135\n",
      "Epoch 5/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.9417 - accuracy: 0.8560 - val_loss: 0.5649 - val_accuracy: 0.8060\n",
      "Epoch 6/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.7790 - accuracy: 0.8685 - val_loss: 0.5046 - val_accuracy: 0.8115\n",
      "Epoch 7/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.6285 - accuracy: 0.8815 - val_loss: 0.5902 - val_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.5141 - accuracy: 0.8873 - val_loss: 0.5672 - val_accuracy: 0.8173\n",
      "Epoch 9/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.3658 - accuracy: 0.8981 - val_loss: 0.6725 - val_accuracy: 0.8025\n",
      "249/249 [==============================] - 3s 10ms/step\n",
      "Fold 3: Accuracy: 0.811495983935743\n",
      "Fold 3: F1-Score: 0.8151901275123891\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 16s 14ms/step - loss: 3.6659 - accuracy: 0.7309 - val_loss: 0.5051 - val_accuracy: 0.8166\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.7845 - accuracy: 0.7952 - val_loss: 0.4703 - val_accuracy: 0.8340\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.4198 - accuracy: 0.8226 - val_loss: 0.4922 - val_accuracy: 0.8374\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.1759 - accuracy: 0.8398 - val_loss: 0.5005 - val_accuracy: 0.8431\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.0079 - accuracy: 0.8494 - val_loss: 0.4933 - val_accuracy: 0.8395\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.7885 - accuracy: 0.8676 - val_loss: 0.5694 - val_accuracy: 0.8335\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.6895 - accuracy: 0.8710 - val_loss: 0.5578 - val_accuracy: 0.8361\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 15s 14ms/step - loss: 1.5750 - accuracy: 0.8867 - val_loss: 0.5930 - val_accuracy: 0.8413\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: Accuracy: 0.8394709543568465\n",
      "Fold 4: F1-Score: 0.8426136161138619\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "1001/1001 [==============================] - 16s 14ms/step - loss: 3.6960 - accuracy: 0.7345 - val_loss: 0.5501 - val_accuracy: 0.8002\n",
      "Epoch 2/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.7465 - accuracy: 0.7969 - val_loss: 0.4797 - val_accuracy: 0.8265\n",
      "Epoch 3/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.4232 - accuracy: 0.8216 - val_loss: 0.4828 - val_accuracy: 0.8245\n",
      "Epoch 4/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.1753 - accuracy: 0.8363 - val_loss: 0.4650 - val_accuracy: 0.8353\n",
      "Epoch 5/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.9683 - accuracy: 0.8535 - val_loss: 0.4835 - val_accuracy: 0.8288\n",
      "Epoch 6/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.8086 - accuracy: 0.8627 - val_loss: 0.5545 - val_accuracy: 0.8217\n",
      "Epoch 7/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.7132 - accuracy: 0.8719 - val_loss: 0.5499 - val_accuracy: 0.8188\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: Accuracy: 0.835\n",
      "Fold 5: F1-Score: 0.838106670791652\n",
      "Average Accuracy: 0.8330201593120613\n",
      "Average F1-Score: 0.8345297622915421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2738"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"default_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-default_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b: Unprocessed 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:03:15.749600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:15.781017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:15.781098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:15.783884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:15.783955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:15.784008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:16.344899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:16.345025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:16.345034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 12:03:16.345151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 12:03:16.345173: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-22 12:03:16.345181: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-22 12:03:16.345302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:03:19.193036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-22 12:03:19.887180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-22 12:03:20.207850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f46992122a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-22 12:03:20.207886: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-22 12:03:20.214038: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-22 12:03:20.321117: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 17s 14ms/step - loss: 3.4564 - accuracy: 0.7457 - val_loss: 0.5328 - val_accuracy: 0.8140\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.5741 - accuracy: 0.8144 - val_loss: 0.4854 - val_accuracy: 0.8240\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.2703 - accuracy: 0.8333 - val_loss: 0.4467 - val_accuracy: 0.8416\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.0374 - accuracy: 0.8494 - val_loss: 0.5087 - val_accuracy: 0.8252\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.8553 - accuracy: 0.8647 - val_loss: 0.4842 - val_accuracy: 0.8359\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6677 - accuracy: 0.8746 - val_loss: 0.5072 - val_accuracy: 0.8217\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4835 - accuracy: 0.8899 - val_loss: 0.5084 - val_accuracy: 0.8381\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.2967 - accuracy: 0.9012 - val_loss: 0.5336 - val_accuracy: 0.8379\n",
      "251/251 [==============================] - 3s 11ms/step\n",
      "Fold 1: Accuracy: 0.8364043824701195\n",
      "Fold 1: F1-Score: 0.8328285937549774\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "992/992 [==============================] - 15s 14ms/step - loss: 3.5575 - accuracy: 0.7433 - val_loss: 0.5327 - val_accuracy: 0.8130\n",
      "Epoch 2/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.6009 - accuracy: 0.8131 - val_loss: 0.4765 - val_accuracy: 0.8423\n",
      "Epoch 3/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.3051 - accuracy: 0.8327 - val_loss: 0.4747 - val_accuracy: 0.8445\n",
      "Epoch 4/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.0860 - accuracy: 0.8473 - val_loss: 0.4581 - val_accuracy: 0.8445\n",
      "Epoch 5/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.8819 - accuracy: 0.8620 - val_loss: 0.4630 - val_accuracy: 0.8486\n",
      "Epoch 6/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.7820 - accuracy: 0.8687 - val_loss: 0.4630 - val_accuracy: 0.8523\n",
      "Epoch 7/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.5756 - accuracy: 0.8826 - val_loss: 0.4747 - val_accuracy: 0.8477\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Fold 2: Accuracy: 0.8447265625\n",
      "Fold 2: F1-Score: 0.8441836548868815\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "999/999 [==============================] - 16s 14ms/step - loss: 3.4578 - accuracy: 0.7536 - val_loss: 0.5379 - val_accuracy: 0.8050\n",
      "Epoch 2/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.5530 - accuracy: 0.8157 - val_loss: 0.5191 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.2642 - accuracy: 0.8398 - val_loss: 0.4979 - val_accuracy: 0.8243\n",
      "Epoch 4/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.0229 - accuracy: 0.8579 - val_loss: 0.5421 - val_accuracy: 0.8198\n",
      "Epoch 5/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.7745 - accuracy: 0.8709 - val_loss: 0.6174 - val_accuracy: 0.8198\n",
      "Epoch 6/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.6232 - accuracy: 0.8831 - val_loss: 0.5635 - val_accuracy: 0.8228\n",
      "Epoch 7/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.4547 - accuracy: 0.8960 - val_loss: 0.6314 - val_accuracy: 0.8133\n",
      "249/249 [==============================] - 3s 10ms/step\n",
      "Fold 3: Accuracy: 0.8197791164658634\n",
      "Fold 3: F1-Score: 0.8190640975705458\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1008/1008 [==============================] - 16s 14ms/step - loss: 3.5793 - accuracy: 0.7446 - val_loss: 0.4809 - val_accuracy: 0.8275\n",
      "Epoch 2/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.6578 - accuracy: 0.8051 - val_loss: 0.4548 - val_accuracy: 0.8413\n",
      "Epoch 3/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.3128 - accuracy: 0.8324 - val_loss: 0.6152 - val_accuracy: 0.8237\n",
      "Epoch 4/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.0762 - accuracy: 0.8483 - val_loss: 0.5061 - val_accuracy: 0.8449\n",
      "Epoch 5/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.8805 - accuracy: 0.8607 - val_loss: 0.5455 - val_accuracy: 0.8431\n",
      "Epoch 6/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.7019 - accuracy: 0.8761 - val_loss: 0.5740 - val_accuracy: 0.8415\n",
      "Epoch 7/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.5572 - accuracy: 0.8844 - val_loss: 0.5595 - val_accuracy: 0.8519\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: Accuracy: 0.8449170124481328\n",
      "Fold 4: F1-Score: 0.8461616286010555\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "998/998 [==============================] - 16s 14ms/step - loss: 3.4387 - accuracy: 0.7534 - val_loss: 0.5608 - val_accuracy: 0.7887\n",
      "Epoch 2/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.5740 - accuracy: 0.8143 - val_loss: 0.5485 - val_accuracy: 0.8060\n",
      "Epoch 3/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.2225 - accuracy: 0.8391 - val_loss: 0.5465 - val_accuracy: 0.8050\n",
      "Epoch 4/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.9986 - accuracy: 0.8518 - val_loss: 0.5690 - val_accuracy: 0.8015\n",
      "Epoch 5/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.8440 - accuracy: 0.8649 - val_loss: 0.4911 - val_accuracy: 0.8238\n",
      "Epoch 6/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.6514 - accuracy: 0.8759 - val_loss: 0.5689 - val_accuracy: 0.8225\n",
      "Epoch 7/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.5239 - accuracy: 0.8897 - val_loss: 0.6360 - val_accuracy: 0.8177\n",
      "Epoch 8/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.4332 - accuracy: 0.8930 - val_loss: 0.6509 - val_accuracy: 0.8213\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: Accuracy: 0.82375\n",
      "Fold 5: F1-Score: 0.8264685526435415\n",
      "Average Accuracy: 0.8339154147768231\n",
      "Average F1-Score: 0.8337413054914004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2738"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2c: Unprocessed 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:05:47.320456: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-22 14:05:47.976321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from shared.data import add_stage_dimension, preprocess\n",
    "from shared.training import split_data_on_participants, train_and_evaluate, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.models import SAT1Base, SAT1Topological, SAT1Deep\n",
    "from shared.utilities import print_results\n",
    "import gc\n",
    "import numpy as np\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "data = xr.load_dataset(data_path)\n",
    "logs_path = Path(\"logs/exp_preprocessing/\")\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_500hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_500hz\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:09:08.061577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:08.162950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:08.163030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:08.165627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:08.165695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:08.165744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:09.112850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:09.112939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:09.112948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 13:09:09.113002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:09:09.113013: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-22 13:09:09.113018: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-22 13:09:09.113134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:09:17.135346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-22 13:09:19.200727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-22 13:09:20.789983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1aa6b96a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-22 13:09:20.790024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-22 13:09:20.819824: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-22 13:09:21.009145: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993/993 [==============================] - 64s 57ms/step - loss: 3.1537 - accuracy: 0.7737 - val_loss: 0.5538 - val_accuracy: 0.7847\n",
      "Epoch 2/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.5313 - accuracy: 0.8098 - val_loss: 0.5399 - val_accuracy: 0.7730\n",
      "Epoch 3/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.2780 - accuracy: 0.8269 - val_loss: 0.4752 - val_accuracy: 0.8012\n",
      "Epoch 4/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 2.0674 - accuracy: 0.8419 - val_loss: 0.4484 - val_accuracy: 0.8190\n",
      "Epoch 5/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.8335 - accuracy: 0.8615 - val_loss: 0.4227 - val_accuracy: 0.8335\n",
      "Epoch 6/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.7236 - accuracy: 0.8675 - val_loss: 0.4434 - val_accuracy: 0.8278\n",
      "Epoch 7/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.5423 - accuracy: 0.8849 - val_loss: 0.4123 - val_accuracy: 0.8413\n",
      "Epoch 8/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.4012 - accuracy: 0.8943 - val_loss: 0.4248 - val_accuracy: 0.8400\n",
      "Epoch 9/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.2962 - accuracy: 0.9050 - val_loss: 0.4786 - val_accuracy: 0.8330\n",
      "Epoch 10/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 1.1349 - accuracy: 0.9172 - val_loss: 0.5169 - val_accuracy: 0.8227\n",
      "250/250 [==============================] - 3s 13ms/step\n",
      "Fold 1: Accuracy: 0.841\n",
      "Fold 1: F1-Score: 0.8219912512255565\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "988/988 [==============================] - 74s 73ms/step - loss: 3.0865 - accuracy: 0.7794 - val_loss: 0.5009 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "988/988 [==============================] - 72s 73ms/step - loss: 2.4102 - accuracy: 0.8250 - val_loss: 0.4672 - val_accuracy: 0.8137\n",
      "Epoch 3/20\n",
      "988/988 [==============================] - 73s 73ms/step - loss: 2.0876 - accuracy: 0.8419 - val_loss: 0.4096 - val_accuracy: 0.8387\n",
      "Epoch 4/20\n",
      "988/988 [==============================] - 74s 74ms/step - loss: 1.9114 - accuracy: 0.8567 - val_loss: 0.4106 - val_accuracy: 0.8380\n",
      "Epoch 5/20\n",
      "988/988 [==============================] - 73s 73ms/step - loss: 1.7850 - accuracy: 0.8663 - val_loss: 0.4166 - val_accuracy: 0.8353\n",
      "Epoch 6/20\n",
      "988/988 [==============================] - 74s 74ms/step - loss: 1.5603 - accuracy: 0.8802 - val_loss: 0.3945 - val_accuracy: 0.8559\n",
      "Epoch 7/20\n",
      "988/988 [==============================] - 73s 73ms/step - loss: 1.3948 - accuracy: 0.8945 - val_loss: 0.4441 - val_accuracy: 0.8576\n",
      "Epoch 8/20\n",
      "988/988 [==============================] - 73s 73ms/step - loss: 1.2631 - accuracy: 0.9059 - val_loss: 0.4526 - val_accuracy: 0.8485\n",
      "Epoch 9/20\n",
      "988/988 [==============================] - 74s 75ms/step - loss: 1.1342 - accuracy: 0.9157 - val_loss: 0.4737 - val_accuracy: 0.8544\n",
      "255/255 [==============================] - 3s 13ms/step\n",
      "Fold 2: Accuracy: 0.8558823529411764\n",
      "Fold 2: F1-Score: 0.8338465274921759\n",
      "Average Accuracy: 0.8484411764705881\n",
      "Average F1-Score: 0.8279188893588663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3336"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[0, 1],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:30:22.209215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.232962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.233045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.234969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.235042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.235092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.788144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.788234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.788243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 13:30:22.788294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 13:30:22.788305: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-22 13:30:22.788310: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-22 13:30:22.788400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 13:30:29.239415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-22 13:30:30.556445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-22 13:30:31.867626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7022c32ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-22 13:30:31.867664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-22 13:30:31.873752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-22 13:30:31.983137: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 63s 57ms/step - loss: 3.1854 - accuracy: 0.7722 - val_loss: 0.4723 - val_accuracy: 0.8206\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 2.5158 - accuracy: 0.8143 - val_loss: 0.4432 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 2.1500 - accuracy: 0.8347 - val_loss: 0.4115 - val_accuracy: 0.8392\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 1.9844 - accuracy: 0.8503 - val_loss: 0.4179 - val_accuracy: 0.8397\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.8589 - accuracy: 0.8587 - val_loss: 0.4380 - val_accuracy: 0.8314\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 56s 56ms/step - loss: 1.6516 - accuracy: 0.8707 - val_loss: 0.4409 - val_accuracy: 0.8445\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 1.5104 - accuracy: 0.8845 - val_loss: 0.4771 - val_accuracy: 0.8311\n",
      "248/248 [==============================] - 3s 13ms/step\n",
      "Fold 3: Accuracy: 0.8399697580645161\n",
      "Fold 3: F1-Score: 0.8243986016414416\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1004/1004 [==============================] - 59s 56ms/step - loss: 3.2937 - accuracy: 0.7648 - val_loss: 0.4391 - val_accuracy: 0.8219\n",
      "Epoch 2/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.5904 - accuracy: 0.8062 - val_loss: 0.4443 - val_accuracy: 0.8206\n",
      "Epoch 3/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.3700 - accuracy: 0.8213 - val_loss: 0.4599 - val_accuracy: 0.8256\n",
      "Epoch 4/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 2.1519 - accuracy: 0.8359 - val_loss: 0.3836 - val_accuracy: 0.8426\n",
      "Epoch 5/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 1.8779 - accuracy: 0.8577 - val_loss: 0.3713 - val_accuracy: 0.8708\n",
      "Epoch 6/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 1.6767 - accuracy: 0.8760 - val_loss: 0.3364 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 1.4583 - accuracy: 0.8932 - val_loss: 0.3628 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 1.2804 - accuracy: 0.9087 - val_loss: 0.3370 - val_accuracy: 0.8834\n",
      "Epoch 9/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 1.0822 - accuracy: 0.9234 - val_loss: 0.3405 - val_accuracy: 0.8844\n",
      "239/239 [==============================] - 3s 13ms/step\n",
      "Fold 4: Accuracy: 0.8697698744769874\n",
      "Fold 4: F1-Score: 0.8549819536621215\n",
      "Average Accuracy: 0.8548698162707518\n",
      "Average F1-Score: 0.8396902776517816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3336"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[2, 3],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:06:00.253962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.280441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.280528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.282928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.282998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.283046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.779326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.779418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.779427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-22 14:06:00.779478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-22 14:06:00.779489: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-22 14:06:00.779494: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-22 14:06:00.779591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:06:07.823139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-22 14:06:09.105714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-22 14:06:10.426596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6002dab290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-22 14:06:10.426629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-22 14:06:10.432873: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-22 14:06:10.542178: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 [==============================] - 62s 56ms/step - loss: 3.1570 - accuracy: 0.7769 - val_loss: 0.5439 - val_accuracy: 0.7799\n",
      "Epoch 2/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 2.4661 - accuracy: 0.8109 - val_loss: 0.4792 - val_accuracy: 0.8062\n",
      "Epoch 3/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 2.1292 - accuracy: 0.8383 - val_loss: 0.4829 - val_accuracy: 0.8160\n",
      "Epoch 4/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.9469 - accuracy: 0.8501 - val_loss: 0.4913 - val_accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.7861 - accuracy: 0.8628 - val_loss: 0.4812 - val_accuracy: 0.8200\n",
      "Epoch 6/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.5994 - accuracy: 0.8760 - val_loss: 0.4523 - val_accuracy: 0.8253\n",
      "Epoch 7/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 1.4649 - accuracy: 0.8878 - val_loss: 0.4798 - val_accuracy: 0.8301\n",
      "Epoch 8/20\n",
      "994/994 [==============================] - 56s 56ms/step - loss: 1.3020 - accuracy: 0.8991 - val_loss: 0.4792 - val_accuracy: 0.8286\n",
      "Epoch 9/20\n",
      "994/994 [==============================] - 57s 57ms/step - loss: 1.2126 - accuracy: 0.9083 - val_loss: 0.5055 - val_accuracy: 0.8336\n",
      "249/249 [==============================] - 3s 13ms/step\n",
      "Fold 5: Accuracy: 0.8255522088353414\n",
      "Fold 5: F1-Score: 0.806006600446103\n",
      "Average Accuracy: 0.8255522088353414\n",
      "Average F1-Score: 0.806006600446103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "results = k_fold_cross_validate(\n",
    "    data,\n",
    "    model,\n",
    "    5,\n",
    "    normalization_fn=norm_dummy,\n",
    "    train_kwargs=train_kwargs,\n",
    "    fold_indices=[4],\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464348388636042\n",
      "0.8282449868934796\n"
     ]
    }
   ],
   "source": [
    "accuracies = [\n",
    "    0.841,\n",
    "    0.8558823529411764,\n",
    "    0.8399697580645161,\n",
    "    0.8697698744769874,\n",
    "    0.8255522088353414\n",
    "]\n",
    "f1_scores = [\n",
    "    0.8219912512255565,\n",
    "    0.8338465274921759,\n",
    "    0.8243986016414416,\n",
    "    0.8549819536621215,\n",
    "    0.806006600446103\n",
    "]\n",
    "print(np.mean(accuracies))\n",
    "print(np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deprecated due to memory leak issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "# model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_500hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_500hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:59:04.226414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# View results in Tensorboard\n",
    "! tensorboard --logdir logs/exp_preprocessing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
