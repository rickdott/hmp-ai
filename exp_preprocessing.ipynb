{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Pre-processing and frequency sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is it possible to train a model on unpreprocessed EEG data and still attain similar performance levels?\n",
    "\n",
    "**Hypothesis**: The model will perform worse, but if still similar then the added value of not having to (manually) preprocess EEG data is very valuable and opens up a multitude of applications.\n",
    "\n",
    "**Result**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Preparing data\n",
    "To use hmp.utils.read_mne_data() and epoch the information, the files should be in .fif format, this replicates automated preprocessing as done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb excepting resampling to 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:50:09.556093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-17 19:50:10.520359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import hsmm_mvpy as hmp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from shared.data import add_stage_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and file locations\n",
    "data_path = Path(\"/mnt/d/thesis/sat1/\")\n",
    "behavioral_data_path = data_path / \"ExperimentData/ExperimentData\"\n",
    "output_path = Path(\"data/sat1/unpreprocessed\")\n",
    "\n",
    "subj_ids = [\n",
    "    subj_id.name.split(\"-\")[1][:4] for subj_id in (data_path / \"eeg4\").glob(\"*.vhdr\")\n",
    "]\n",
    "subj_files = [\n",
    "    str(output_path / f\"unprocessed_{subj_id}_epo.fif\") for subj_id in subj_ids\n",
    "]\n",
    "behavioral_files = [\n",
    "    str(behavioral_data_path / f\"{subj_id}-cnv-sat3_ET.csv\") for subj_id in subj_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing preprocessing done in https://github.com/GWeindel/hsmm_mvpy/blob/main/tutorials/sample_data/eeg/0022.ipynb\n",
    "# with only the necessary (non-manual) parts, like adding metadata for processing in HMP package, more info in link above\n",
    "for subject_id in subj_ids:\n",
    "    print(f\"Processing subject: {subject_id}\")\n",
    "    subject_id_short = subject_id.replace(\"0\", \"\")\n",
    "    raw = mne.io.read_raw_brainvision(\n",
    "        data_path / \"eeg4\" / f\"MD3-{subject_id}.vhdr\", preload=False\n",
    "    )\n",
    "    raw.set_channel_types(\n",
    "        {\"EOGh\": \"eog\", \"EOGv\": \"eog\", \"A1\": \"misc\", \"A2\": \"misc\"}\n",
    "    )  # Declare type to avoid confusion with EEG channels\n",
    "    raw.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    raw.set_montage(\"standard_1020\")  # Standard 10-20 electrode montage\n",
    "    raw.rename_channels({\"Fp1\": \"FP1\", \"Fp2\": \"FP2\"})\n",
    "\n",
    "    behavioral_path = behavioral_data_path / f\"{subject_id}-cnv-sat3_ET.csv\"\n",
    "    behavior = pd.read_csv(behavioral_path, sep=\";\")[\n",
    "        [\n",
    "            \"stim\",\n",
    "            \"resp\",\n",
    "            \"RT\",\n",
    "            \"cue\",\n",
    "            \"movement\",\n",
    "        ]\n",
    "    ]\n",
    "    behavior[\"movement\"] = behavior.apply(\n",
    "        lambda row: \"stim_left\"\n",
    "        if row[\"movement\"] == -1\n",
    "        else (\"stim_right\" if row[\"movement\"] == 1 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    behavior[\"resp\"] = behavior.apply(\n",
    "        lambda row: \"resp_left\"\n",
    "        if row[\"resp\"] == 1\n",
    "        else (\"resp_right\" if row[\"resp\"] == 2 else np.nan),\n",
    "        axis=1,\n",
    "    )\n",
    "    # Merging together the exeperimental conditions info to have the format condition/stimulus/response\n",
    "    behavior[\"trigger\"] = (\n",
    "        behavior[\"cue\"] + \"/\" + behavior[\"movement\"] + \"/\" + behavior[\"resp\"]\n",
    "    )\n",
    "    # Filtering out < 300 and > 3000 Reaction times\n",
    "    behavior[\"RT\"] = behavior.apply(\n",
    "        lambda row: 0\n",
    "        if row[\"RT\"] < 300\n",
    "        else (0 if row[\"RT\"] > 3000 else float(row[\"RT\"]) / 1000),\n",
    "        axis=1,\n",
    "    )\n",
    "    epochs = mne.io.read_epochs_fieldtrip(\n",
    "        data_path / \"eeg1\" / f\"data{subject_id_short}.mat\", info=raw.info\n",
    "    )\n",
    "    epochs.rename_channels({\"FP1\": \"Fp1\", \"FP2\": \"Fp2\"})  # Naming convention\n",
    "    epochs.set_montage(\"easycap-M1\")\n",
    "    epochs.filter(1, 35)  # Bandwidth filter from van Maanen, Portoles & Borst (2021)\n",
    "    epochs.crop(tmin=-0.250)\n",
    "    epochs.set_eeg_reference(\"average\")\n",
    "    epochs.metadata = behavior\n",
    "    epochs.save(\n",
    "        output_path / f\"unprocessed_{subject_id}_epo.fif\", overwrite=True, verbose=False\n",
    "    )  # Saving EEG mne format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_500hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0001_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0002_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif's epoched eeg\n",
      "191 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0003_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0004_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif's epoched eeg\n",
      "190 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0005_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0006_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0007_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0008_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0009_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0010_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0011_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif's epoched eeg\n",
      "188 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0012_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0013_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif's epoched eeg\n",
      "186 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0014_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0015_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0016_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0017_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0018_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif's epoched eeg\n",
      "197 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0019_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif's epoched eeg\n",
      "178 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0020_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0021_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif's epoched eeg\n",
      "200 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0022_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif's epoched eeg\n",
      "198 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0023_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif's epoched eeg\n",
      "185 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0024_epo.fif\n",
      "Processing participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif's epoched eeg\n",
      "199 trials were retained for participant data/sat1/unpreprocessed/unprocessed_0025_epo.fif\n"
     ]
    }
   ],
   "source": [
    "output_path_data = Path(\"data/sat1/data_unprocessed_100hz.nc\")\n",
    "# Run if data_unprocessed.nc does not exist or should be rewritten\n",
    "data = hmp.utils.read_mne_data(\n",
    "    subj_files,\n",
    "    epoched=True,\n",
    "    lower_limit_RT=0.2,\n",
    "    upper_limit_RT=2,\n",
    "    sfreq=100,\n",
    "    verbose=False,\n",
    "    subj_idx=subj_ids,\n",
    "    rt_col=\"RT\",\n",
    ")\n",
    "data.to_netcdf(output_path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use information from stage_data to split unprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n",
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_500hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stage changes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining segments\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data/sat1/stage_data.nc\")\n",
    "merge_dataset = xr.load_dataset(Path(\"data/sat1/data_unprocessed_100hz.nc\"))\n",
    "output_data = add_stage_dimension(data_path, merge_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "output_data.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from shared.data import add_stage_dimension\n",
    "from shared.training import split_data_on_participants, train_and_evaluate, k_fold_cross_validate, get_compile_kwargs\n",
    "from shared.normalization import *\n",
    "from shared.models import SAT1Base, SAT1Topological, SAT1Deep\n",
    "from shared.utilities import print_results\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = Path(\"logs/exp_preprocessing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a: Processed 100Hz (control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 17:46:44.898784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.931234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.931331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:44.933930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-17 17:46:45.414548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 17:46:45.414559: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-17 17:46:45.414564: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-17 17:46:45.414675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 17:46:48.212527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-17 17:46:48.893596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-17 17:46:49.215032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556587cdee30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-17 17:46:49.215067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-17 17:46:49.221195: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 17:46:49.328577: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 17s 13ms/step - loss: 3.6975 - accuracy: 0.7287 - val_loss: 0.5757 - val_accuracy: 0.7936\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 13ms/step - loss: 2.8072 - accuracy: 0.7963 - val_loss: 0.5160 - val_accuracy: 0.8086\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.4092 - accuracy: 0.8225 - val_loss: 0.5079 - val_accuracy: 0.8093\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.1977 - accuracy: 0.8389 - val_loss: 0.4915 - val_accuracy: 0.8155\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.9734 - accuracy: 0.8527 - val_loss: 0.4765 - val_accuracy: 0.8204\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.8409 - accuracy: 0.8664 - val_loss: 0.4750 - val_accuracy: 0.8265\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6335 - accuracy: 0.8769 - val_loss: 0.5327 - val_accuracy: 0.8199\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.5267 - accuracy: 0.8880 - val_loss: 0.5130 - val_accuracy: 0.8216\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.3483 - accuracy: 0.8974 - val_loss: 0.5155 - val_accuracy: 0.8322\n",
      "254/254 [==============================] - 3s 10ms/step\n",
      "Fold 1: accuracy: 0.8265255905511811\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 3.8727 - accuracy: 0.7290 - val_loss: 0.5923 - val_accuracy: 0.7805\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.6737 - accuracy: 0.8013 - val_loss: 0.4755 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 14s 13ms/step - loss: 2.4567 - accuracy: 0.8184 - val_loss: 0.4463 - val_accuracy: 0.8323\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.2811 - accuracy: 0.8282 - val_loss: 0.4512 - val_accuracy: 0.8328\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.2080 - accuracy: 0.8352 - val_loss: 0.4537 - val_accuracy: 0.8352\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 2.0390 - accuracy: 0.8455 - val_loss: 0.4554 - val_accuracy: 0.8342\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.9194 - accuracy: 0.8571 - val_loss: 0.4463 - val_accuracy: 0.8394\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.8069 - accuracy: 0.8635 - val_loss: 0.4530 - val_accuracy: 0.8447\n",
      "Epoch 9/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.6828 - accuracy: 0.8735 - val_loss: 0.4679 - val_accuracy: 0.8418\n",
      "Epoch 10/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.5931 - accuracy: 0.8778 - val_loss: 0.4430 - val_accuracy: 0.8438\n",
      "Epoch 11/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.4559 - accuracy: 0.8869 - val_loss: 0.4841 - val_accuracy: 0.8491\n",
      "Epoch 12/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.3466 - accuracy: 0.8978 - val_loss: 0.5389 - val_accuracy: 0.8369\n",
      "Epoch 13/20\n",
      "995/995 [==============================] - 14s 14ms/step - loss: 1.2917 - accuracy: 0.9004 - val_loss: 0.5121 - val_accuracy: 0.8411\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Fold 2: accuracy: 0.84375\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 4.1664 - accuracy: 0.6975 - val_loss: 0.5973 - val_accuracy: 0.7676\n",
      "Epoch 2/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 3.0478 - accuracy: 0.7765 - val_loss: 0.5512 - val_accuracy: 0.7846\n",
      "Epoch 3/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.6682 - accuracy: 0.8023 - val_loss: 0.5000 - val_accuracy: 0.8057\n",
      "Epoch 4/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.4336 - accuracy: 0.8223 - val_loss: 0.4922 - val_accuracy: 0.8085\n",
      "Epoch 5/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.2648 - accuracy: 0.8299 - val_loss: 0.4918 - val_accuracy: 0.8100\n",
      "Epoch 6/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.1633 - accuracy: 0.8381 - val_loss: 0.5074 - val_accuracy: 0.8095\n",
      "Epoch 7/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 2.0062 - accuracy: 0.8489 - val_loss: 0.5611 - val_accuracy: 0.7994\n",
      "Epoch 8/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.8843 - accuracy: 0.8552 - val_loss: 0.4908 - val_accuracy: 0.8175\n",
      "Epoch 9/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.8041 - accuracy: 0.8641 - val_loss: 0.5002 - val_accuracy: 0.8215\n",
      "Epoch 10/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.6816 - accuracy: 0.8718 - val_loss: 0.5391 - val_accuracy: 0.8090\n",
      "Epoch 11/20\n",
      "1002/1002 [==============================] - 14s 14ms/step - loss: 1.5958 - accuracy: 0.8789 - val_loss: 0.5909 - val_accuracy: 0.8050\n",
      "249/249 [==============================] - 3s 11ms/step\n",
      "Fold 3: accuracy: 0.8175200803212851\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 3.9305 - accuracy: 0.7184 - val_loss: 0.5009 - val_accuracy: 0.8169\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.8161 - accuracy: 0.7941 - val_loss: 0.5508 - val_accuracy: 0.7884\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.5596 - accuracy: 0.8089 - val_loss: 0.4586 - val_accuracy: 0.8356\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.3705 - accuracy: 0.8216 - val_loss: 0.4426 - val_accuracy: 0.8452\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.2098 - accuracy: 0.8339 - val_loss: 0.4506 - val_accuracy: 0.8379\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 2.1070 - accuracy: 0.8444 - val_loss: 0.4402 - val_accuracy: 0.8444\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.9849 - accuracy: 0.8523 - val_loss: 0.4605 - val_accuracy: 0.8454\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.8860 - accuracy: 0.8570 - val_loss: 0.4502 - val_accuracy: 0.8511\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 14s 14ms/step - loss: 1.7837 - accuracy: 0.8667 - val_loss: 0.4953 - val_accuracy: 0.8421\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8443983402489627\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 3.8962 - accuracy: 0.7237 - val_loss: 0.5502 - val_accuracy: 0.8023\n",
      "Epoch 2/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.7261 - accuracy: 0.7985 - val_loss: 0.4814 - val_accuracy: 0.8205\n",
      "Epoch 3/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.3934 - accuracy: 0.8212 - val_loss: 0.4476 - val_accuracy: 0.8317\n",
      "Epoch 4/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.1773 - accuracy: 0.8351 - val_loss: 0.4670 - val_accuracy: 0.8227\n",
      "Epoch 5/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 2.0778 - accuracy: 0.8463 - val_loss: 0.4515 - val_accuracy: 0.8270\n",
      "Epoch 6/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.8452 - accuracy: 0.8607 - val_loss: 0.4730 - val_accuracy: 0.8280\n",
      "Epoch 7/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.7761 - accuracy: 0.8648 - val_loss: 0.4662 - val_accuracy: 0.8278\n",
      "Epoch 8/20\n",
      "1001/1001 [==============================] - 14s 14ms/step - loss: 1.6842 - accuracy: 0.8709 - val_loss: 0.4733 - val_accuracy: 0.8388\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.827\n",
      "Average Accuracy: 0.8318388022242857\n",
      "Average F1-Score: 0.8321140270388406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"default_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-default_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b: Unprocessed 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_100hz.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n",
      "997/997 [==============================] - 15s 14ms/step - loss: 3.4801 - accuracy: 0.7509 - val_loss: 0.5346 - val_accuracy: 0.8065\n",
      "Epoch 2/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.6244 - accuracy: 0.8129 - val_loss: 0.5000 - val_accuracy: 0.8252\n",
      "Epoch 3/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.3060 - accuracy: 0.8306 - val_loss: 0.4662 - val_accuracy: 0.8384\n",
      "Epoch 4/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 2.1392 - accuracy: 0.8437 - val_loss: 0.4516 - val_accuracy: 0.8431\n",
      "Epoch 5/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.9021 - accuracy: 0.8601 - val_loss: 0.4549 - val_accuracy: 0.8386\n",
      "Epoch 6/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.7453 - accuracy: 0.8738 - val_loss: 0.4557 - val_accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.6421 - accuracy: 0.8776 - val_loss: 0.4490 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4681 - accuracy: 0.8887 - val_loss: 0.4692 - val_accuracy: 0.8484\n",
      "Epoch 9/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.4217 - accuracy: 0.8989 - val_loss: 0.4579 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "997/997 [==============================] - 14s 14ms/step - loss: 1.2412 - accuracy: 0.9077 - val_loss: 0.4572 - val_accuracy: 0.8446\n",
      "251/251 [==============================] - 3s 10ms/step\n",
      "Fold 1: accuracy: 0.8533366533864541\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 3.9052 - accuracy: 0.7195 - val_loss: 0.6112 - val_accuracy: 0.7737\n",
      "Epoch 2/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.8202 - accuracy: 0.7913 - val_loss: 0.4972 - val_accuracy: 0.8225\n",
      "Epoch 3/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.4260 - accuracy: 0.8187 - val_loss: 0.4926 - val_accuracy: 0.8210\n",
      "Epoch 4/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.2892 - accuracy: 0.8258 - val_loss: 0.4808 - val_accuracy: 0.8271\n",
      "Epoch 5/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 2.0932 - accuracy: 0.8419 - val_loss: 0.4423 - val_accuracy: 0.8452\n",
      "Epoch 6/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.9960 - accuracy: 0.8514 - val_loss: 0.4419 - val_accuracy: 0.8459\n",
      "Epoch 7/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.8740 - accuracy: 0.8587 - val_loss: 0.4538 - val_accuracy: 0.8406\n",
      "Epoch 8/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.8103 - accuracy: 0.8638 - val_loss: 0.4482 - val_accuracy: 0.8501\n",
      "Epoch 9/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.5907 - accuracy: 0.8773 - val_loss: 0.4390 - val_accuracy: 0.8535\n",
      "Epoch 10/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.5033 - accuracy: 0.8858 - val_loss: 0.4365 - val_accuracy: 0.8577\n",
      "Epoch 11/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.4056 - accuracy: 0.8911 - val_loss: 0.4541 - val_accuracy: 0.8547\n",
      "Epoch 12/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.2970 - accuracy: 0.9003 - val_loss: 0.4965 - val_accuracy: 0.8542\n",
      "Epoch 13/20\n",
      "992/992 [==============================] - 14s 14ms/step - loss: 1.2895 - accuracy: 0.9042 - val_loss: 0.5028 - val_accuracy: 0.8518\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Fold 2: accuracy: 0.857666015625\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 3.5474 - accuracy: 0.7528 - val_loss: 0.5517 - val_accuracy: 0.7999\n",
      "Epoch 2/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.6378 - accuracy: 0.8112 - val_loss: 0.5351 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.3160 - accuracy: 0.8311 - val_loss: 0.4999 - val_accuracy: 0.8173\n",
      "Epoch 4/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.1267 - accuracy: 0.8435 - val_loss: 0.4660 - val_accuracy: 0.8361\n",
      "Epoch 5/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 2.0084 - accuracy: 0.8505 - val_loss: 0.4922 - val_accuracy: 0.8198\n",
      "Epoch 6/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.8611 - accuracy: 0.8631 - val_loss: 0.4985 - val_accuracy: 0.8233\n",
      "Epoch 7/20\n",
      "999/999 [==============================] - 14s 14ms/step - loss: 1.7578 - accuracy: 0.8693 - val_loss: 0.4891 - val_accuracy: 0.8296\n",
      "249/249 [==============================] - 3s 11ms/step\n",
      "Fold 3: accuracy: 0.8360943775100401\n",
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 3.7614 - accuracy: 0.7405 - val_loss: 0.4651 - val_accuracy: 0.8327\n",
      "Epoch 2/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.6389 - accuracy: 0.8047 - val_loss: 0.5074 - val_accuracy: 0.8195\n",
      "Epoch 3/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.4270 - accuracy: 0.8218 - val_loss: 0.4696 - val_accuracy: 0.8332\n",
      "Epoch 4/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.2047 - accuracy: 0.8359 - val_loss: 0.4226 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.0879 - accuracy: 0.8447 - val_loss: 0.4064 - val_accuracy: 0.8527\n",
      "Epoch 6/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 2.0028 - accuracy: 0.8467 - val_loss: 0.4153 - val_accuracy: 0.8576\n",
      "Epoch 7/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.8328 - accuracy: 0.8609 - val_loss: 0.4278 - val_accuracy: 0.8641\n",
      "Epoch 8/20\n",
      "1008/1008 [==============================] - 14s 14ms/step - loss: 1.7824 - accuracy: 0.8643 - val_loss: 0.4638 - val_accuracy: 0.8426\n",
      "241/241 [==============================] - 3s 11ms/step\n",
      "Fold 4: accuracy: 0.8526970954356846\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n",
      "Epoch 1/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 3.4941 - accuracy: 0.7578 - val_loss: 0.5525 - val_accuracy: 0.7937\n",
      "Epoch 2/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.5227 - accuracy: 0.8165 - val_loss: 0.5137 - val_accuracy: 0.8117\n",
      "Epoch 3/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.2106 - accuracy: 0.8349 - val_loss: 0.4971 - val_accuracy: 0.8167\n",
      "Epoch 4/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 2.0230 - accuracy: 0.8526 - val_loss: 0.4871 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.8643 - accuracy: 0.8618 - val_loss: 0.5087 - val_accuracy: 0.8207\n",
      "975/998 [============================>.] - ETA: 0s - loss: 1.8593 - accuracy: 0.8617Epoch 6/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.7266 - accuracy: 0.8719 - val_loss: 0.5067 - val_accuracy: 0.8213\n",
      "Epoch 7/20\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.5975 - accuracy: 0.8813 - val_loss: 0.5027 - val_accuracy: 0.8310\n",
      "250/250 [==============================] - 3s 11ms/step\n",
      "Fold 5: accuracy: 0.8255\n",
      "Average Accuracy: 0.8450588283914359\n",
      "Average F1-Score: 0.8452467751439409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38733"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Base(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_100hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_100hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2c: Unprocessed 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/sat1/split_stage_data_unprocessed_500hz.nc\")\n",
    "data = xr.load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:50:35.480610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:35.575973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:35.576052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:35.578873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:35.578942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:35.578987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:36.334351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:36.334440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:36.334448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-17 19:50:36.334501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-17 19:50:36.334512: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-17 19:50:36.334517: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-10-17 19:50:36.334642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21598 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['0009' '0017' '0001' '0024' '0012']\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:50:43.778961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-17 19:50:45.664551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-17 19:50:47.138091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5634588f2a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-17 19:50:47.138125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-17 19:50:47.165439: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 19:50:47.346839: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993/993 [==============================] - 63s 56ms/step - loss: 3.1594 - accuracy: 0.7758 - val_loss: 0.4848 - val_accuracy: 0.8055\n",
      "Epoch 2/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.4843 - accuracy: 0.8157 - val_loss: 0.4742 - val_accuracy: 0.8010\n",
      "Epoch 3/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 2.2129 - accuracy: 0.8331 - val_loss: 0.4835 - val_accuracy: 0.8145\n",
      "Epoch 4/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 2.0398 - accuracy: 0.8446 - val_loss: 0.4093 - val_accuracy: 0.8365\n",
      "Epoch 5/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 1.8573 - accuracy: 0.8550 - val_loss: 0.4016 - val_accuracy: 0.8390\n",
      "Epoch 6/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.6898 - accuracy: 0.8708 - val_loss: 0.4098 - val_accuracy: 0.8363\n",
      "Epoch 7/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.5624 - accuracy: 0.8801 - val_loss: 0.4054 - val_accuracy: 0.8468\n",
      "Epoch 8/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 1.3934 - accuracy: 0.8937 - val_loss: 0.3958 - val_accuracy: 0.8443\n",
      "Epoch 9/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.1914 - accuracy: 0.9087 - val_loss: 0.4429 - val_accuracy: 0.8430\n",
      "Epoch 10/20\n",
      "993/993 [==============================] - 56s 56ms/step - loss: 1.1584 - accuracy: 0.9138 - val_loss: 0.4982 - val_accuracy: 0.8285\n",
      "Epoch 11/20\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 0.9675 - accuracy: 0.9291 - val_loss: 0.5464 - val_accuracy: 0.8480\n",
      "250/250 [==============================] - 3s 13ms/step\n",
      "Fold 1: accuracy: 0.84425\n",
      "Fold 2: test fold: ['0010' '0014' '0002' '0023' '0006']\n",
      "Epoch 1/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 11.1465 - accuracy: 0.7652 - val_loss: 0.5012 - val_accuracy: 0.8027\n",
      "Epoch 2/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 2.4147 - accuracy: 0.8152 - val_loss: 0.4709 - val_accuracy: 0.8108\n",
      "Epoch 3/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 2.2723 - accuracy: 0.8234 - val_loss: 0.4629 - val_accuracy: 0.8135\n",
      "Epoch 4/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 2.1749 - accuracy: 0.8332 - val_loss: 0.4353 - val_accuracy: 0.8240\n",
      "Epoch 5/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 2.0364 - accuracy: 0.8436 - val_loss: 0.4333 - val_accuracy: 0.8287\n",
      "Epoch 6/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 1.8915 - accuracy: 0.8537 - val_loss: 0.4147 - val_accuracy: 0.8365\n",
      "Epoch 7/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 1.7219 - accuracy: 0.8664 - val_loss: 0.4220 - val_accuracy: 0.8309\n",
      "Epoch 8/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 1.6467 - accuracy: 0.8792 - val_loss: 0.4905 - val_accuracy: 0.8343\n",
      "Epoch 9/20\n",
      "988/988 [==============================] - 57s 57ms/step - loss: 1.5244 - accuracy: 0.8859 - val_loss: 0.4117 - val_accuracy: 0.8463\n",
      "Epoch 10/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 1.3426 - accuracy: 0.9014 - val_loss: 0.4580 - val_accuracy: 0.8485\n",
      "Epoch 11/20\n",
      "988/988 [==============================] - 56s 57ms/step - loss: 1.2438 - accuracy: 0.9066 - val_loss: 0.5035 - val_accuracy: 0.8502\n",
      "Epoch 12/20\n",
      "988/988 [==============================] - 57s 58ms/step - loss: 1.1111 - accuracy: 0.9192 - val_loss: 0.4383 - val_accuracy: 0.8522\n",
      "255/255 [==============================] - 3s 13ms/step\n",
      "Fold 2: accuracy: 0.8463235294117647\n",
      "Fold 3: test fold: ['0003' '0013' '0016' '0004' '0005']\n",
      "Epoch 1/20\n",
      "995/995 [==============================] - 57s 56ms/step - loss: 9.3979 - accuracy: 0.1992 - val_loss: 1.6104 - val_accuracy: 0.1164\n",
      "Epoch 2/20\n",
      "995/995 [==============================] - 57s 56ms/step - loss: 8.0495 - accuracy: 0.1885 - val_loss: 1.6094 - val_accuracy: 0.2210\n",
      "Epoch 3/20\n",
      "995/995 [==============================] - 57s 56ms/step - loss: 8.0482 - accuracy: 0.1812 - val_loss: 1.6070 - val_accuracy: 0.2235\n",
      "Epoch 4/20\n",
      "995/995 [==============================] - 58s 57ms/step - loss: 8.0486 - accuracy: 0.2102 - val_loss: 1.6100 - val_accuracy: 0.1164\n",
      "Epoch 5/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 8.0734 - accuracy: 0.1977 - val_loss: 1.6087 - val_accuracy: 0.2235\n",
      "Epoch 6/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 8.0486 - accuracy: 0.1829 - val_loss: 1.6083 - val_accuracy: 0.2235\n",
      "Epoch 7/20\n",
      "995/995 [==============================] - 57s 56ms/step - loss: 8.0488 - accuracy: 0.1974 - val_loss: 1.6098 - val_accuracy: 0.2251\n",
      "Epoch 8/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 8.0490 - accuracy: 0.1719 - val_loss: 1.6084 - val_accuracy: 0.2210\n",
      "Epoch 9/20\n",
      "995/995 [==============================] - 57s 57ms/step - loss: 8.0483 - accuracy: 0.2011 - val_loss: 1.6090 - val_accuracy: 0.2140\n",
      "248/248 [==============================] - 3s 13ms/step\n",
      "Fold 3: accuracy: 0.2235383064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rick/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rick/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: test fold: ['0021' '0018' '0022' '0019' '0025']\n",
      "Epoch 1/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 7.4481 - accuracy: 0.7554 - val_loss: 0.4174 - val_accuracy: 0.8350\n",
      "Epoch 2/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 2.5572 - accuracy: 0.8058 - val_loss: 0.4036 - val_accuracy: 0.8447\n",
      "Epoch 3/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.3823 - accuracy: 0.8159 - val_loss: 0.4032 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "1004/1004 [==============================] - 61s 60ms/step - loss: 2.2454 - accuracy: 0.8250 - val_loss: 0.3676 - val_accuracy: 0.8517\n",
      "Epoch 5/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.1471 - accuracy: 0.8340 - val_loss: 0.3687 - val_accuracy: 0.8483\n",
      "Epoch 6/20\n",
      "1004/1004 [==============================] - 57s 56ms/step - loss: 2.0538 - accuracy: 0.8398 - val_loss: 0.4026 - val_accuracy: 0.8387\n",
      "Epoch 7/20\n",
      "1004/1004 [==============================] - 58s 57ms/step - loss: 1.9841 - accuracy: 0.8454 - val_loss: 0.3835 - val_accuracy: 0.8405\n",
      "239/239 [==============================] - 3s 14ms/step\n",
      "Fold 4: accuracy: 0.8517259414225942\n",
      "Fold 5: test fold: ['0008' '0011' '0015' '0020' '0007']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = SAT1Deep(len(data.channels), len(data.samples), len(data.labels))\n",
    "model.compile(**get_compile_kwargs())\n",
    "train_kwargs = {\n",
    "    \"logs_path\": logs_path,\n",
    "    \"additional_info\": {\"preprocessing\": \"unprocessed_500hz\"},\n",
    "    \"additional_name\": f\"preprocessing-unprocessed_500hz\",\n",
    "}\n",
    "results = k_fold_cross_validate(\n",
    "    data, model, 5, normalization_fn=norm_dummy, train_kwargs=train_kwargs\n",
    ")\n",
    "print_results(results)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:59:04.226414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# View results in Tensorboard\n",
    "! tensorboard --logdir logs/exp_preprocessing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
