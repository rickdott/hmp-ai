{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hmpai.pytorch.generators import SAT1DataLoader\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants\n",
    "from hmpai.pytorch.training import train, validate\n",
    "from hmpai.pytorch.utilities import DEVICE\n",
    "from hmpai.normalization import *\n",
    "import random\n",
    "import numpy as np\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "data_path = Path(\"../data/sat1/split_stage_data.nc\")\n",
    "\n",
    "dataset = xr.load_dataset(data_path)\n",
    "train_data, val_data, test_data = split_data_on_participants(dataset, 60, norm_0_to_1)\n",
    "\n",
    "# eeg_dataset = EegDataset(data)\n",
    "train_loader = SAT1DataLoader(train_data)\n",
    "val_loader = SAT1DataLoader(val_data)\n",
    "test_loader = SAT1DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SAT1Base(len(dataset.channels), len(dataset.samples), len(dataset.labels)).to(\n",
    "#     DEVICE\n",
    "# )\n",
    "model = SAT1Mlp(len(dataset.channels), len(dataset.samples), len(dataset.labels)).to(\n",
    "    DEVICE\n",
    ")\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.NAdam(model.parameters())\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SAT1Mlp                                  [16, 5]                   --\n",
       "├─Flatten: 1-1                           [16, 4410]                --\n",
       "├─Linear: 1-2                            [16, 256]                 1,129,216\n",
       "├─ReLU: 1-3                              [16, 256]                 --\n",
       "├─Linear: 1-4                            [16, 5]                   1,285\n",
       "==========================================================================================\n",
       "Total params: 1,130,501\n",
       "Trainable params: 1,130,501\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 18.09\n",
       "==========================================================================================\n",
       "Input size (MB): 0.28\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 4.52\n",
       "Estimated Total Size (MB): 4.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (16, 1, 147, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed969e37e524f20a944828ac7310837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6616b40b7bac40c0937b9fb8cc78a98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 21.31070074198898, val_loss: 1.3070899970677434, val_accuracy: 0.4824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c6c083e9a4ed0aac92f71cdd8601a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16610b143f05480692334ad59f04c11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 1.2986475286742025, val_loss: 1.1590024670776056, val_accuracy: 0.50918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4755fd79b442238ee7d530dcf23e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44909a498cd24b588c57ee955954c56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: 1.1988962546994852, val_loss: 1.1326504588127135, val_accuracy: 0.52245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426ab21534494cec928fc10595637733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f194df09df0745a8bd4df8b9fb214913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss: 1.1706481753913698, val_loss: 1.1089973503229569, val_accuracy: 0.53036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5b8a5785aa4e378884accfc12d6949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d0dbbb79eb48048ffe1f107cb9de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss: 1.160849751852935, val_loss: 1.1916433601963277, val_accuracy: 0.47755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7fd5cac7904b8ab619aa1a5a3f9588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git/hmp-ai/sat1/4_pytorch_test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/sat1/4_pytorch_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/sat1/4_pytorch_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     batch_losses \u001b[39m=\u001b[39m train(model, train_loader, opt, loss)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/sat1/4_pytorch_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Shuffle data before next epoch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git/hmp-ai/sat1/4_pytorch_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     train_loader\u001b[39m.\u001b[39mshuffle()\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/training.py:11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m loss_per_batch \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m tqdm(train_loader):\n\u001b[1;32m     12\u001b[0m     \u001b[39m# (Index, samples, channels), (Index, )\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m     data, labels \u001b[39m=\u001b[39;49m batch[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE), batch[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    251\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/generators.py:86\u001b[0m, in \u001b[0;36mSAT1DataLoader.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     84\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(idx)\n\u001b[1;32m     85\u001b[0m     batch_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m---> 86\u001b[0m         [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcat_labels\u001b[39m.\u001b[39;49mindex(label) \u001b[39mfor\u001b[39;49;00m label \u001b[39min\u001b[39;49;00m batch\u001b[39m.\u001b[39;49mlabels]\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     batch_data \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     89\u001b[0m     batch_data \u001b[39m=\u001b[39m batch_data[:, \u001b[39mNone\u001b[39;00m, :, :]\n",
      "File \u001b[0;32m/mnt/c/git/hmp-ai/pkg/hmpai/pytorch/generators.py:86\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     84\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(idx)\n\u001b[1;32m     85\u001b[0m     batch_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m---> 86\u001b[0m         [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcat_labels\u001b[39m.\u001b[39;49mindex(label) \u001b[39mfor\u001b[39;49;00m label \u001b[39min\u001b[39;49;00m batch\u001b[39m.\u001b[39;49mlabels]\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     batch_data \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     89\u001b[0m     batch_data \u001b[39m=\u001b[39m batch_data[:, \u001b[39mNone\u001b[39;00m, :, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/common.py:194\u001b[0m, in \u001b[0;36mAbstractArray._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter\u001b[39m(\u001b[39mself\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Any]:\n\u001b[1;32m    193\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[0;32m--> 194\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m[n]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/dataarray.py:823\u001b[0m, in \u001b[0;36mDataArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_coord(key)\n\u001b[1;32m    821\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     \u001b[39m# xarray-style array indexing\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49misel(indexers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_item_key_to_dict(key))\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/dataarray.py:1433\u001b[0m, in \u001b[0;36mDataArray.isel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m coord_indexers \u001b[39m=\u001b[39m {\n\u001b[1;32m   1430\u001b[0m     k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m indexers\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m coord_value\u001b[39m.\u001b[39mdims\n\u001b[1;32m   1431\u001b[0m }\n\u001b[1;32m   1432\u001b[0m \u001b[39mif\u001b[39;00m coord_indexers:\n\u001b[0;32m-> 1433\u001b[0m     coord_value \u001b[39m=\u001b[39m coord_value\u001b[39m.\u001b[39;49misel(coord_indexers)\n\u001b[1;32m   1434\u001b[0m     \u001b[39mif\u001b[39;00m drop \u001b[39mand\u001b[39;00m coord_value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1435\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/variable.py:1378\u001b[0m, in \u001b[0;36mVariable.isel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m indexers \u001b[39m=\u001b[39m drop_dims_from_indexers(indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims, missing_dims)\n\u001b[1;32m   1377\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(indexers\u001b[39m.\u001b[39mget(dim, \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims)\n\u001b[0;32m-> 1378\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/variable.py:900\u001b[0m, in \u001b[0;36mVariable.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a new Variable object whose contents are consistent with\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[39mgetting the provided key from the underlying data.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[39marray `x.values` directly.\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    899\u001b[0m dims, indexer, new_order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_broadcast_indexes(key)\n\u001b[0;32m--> 900\u001b[0m data \u001b[39m=\u001b[39m as_indexable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)[indexer]\n\u001b[1;32m    901\u001b[0m \u001b[39mif\u001b[39;00m new_order:\n\u001b[1;32m    902\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(data, \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(new_order)), new_order)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/indexing.py:1606\u001b[0m, in \u001b[0;36mPandasMultiIndexingAdapter.__getitem__\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, indexer):\n\u001b[0;32m-> 1606\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(indexer)\n\u001b[1;32m   1607\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[1;32m   1608\u001b[0m         result\u001b[39m.\u001b[39mlevel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevel\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/xarray/core/indexing.py:1544\u001b[0m, in \u001b[0;36mPandasIndexingAdapter.__getitem__\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# Return np-array if multidimensional\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m     \u001b[39mreturn\u001b[39;00m NumpyIndexingAdapter(np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m))[indexer]\n\u001b[0;32m-> 1544\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49marray[key]\n\u001b[1;32m   1546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, pd\u001b[39m.\u001b[39mIndex):\n\u001b[1;32m   1547\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(result, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2069\u001b[0m, in \u001b[0;36mMultiIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             retval\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m   2068\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2069\u001b[0m             retval\u001b[39m.\u001b[39mappend(lev[level_codes[key]])\n\u001b[1;32m   2071\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(retval)\n\u001b[1;32m   2072\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2073\u001b[0m     \u001b[39m# in general cannot be sure whether the result will be sorted\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis_pytorch/lib/python3.11/site-packages/pandas/core/indexes/base.py:5349\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   5346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex does not support mutable operations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 5349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5351\u001b[0m \u001b[39m    Override numpy.ndarray's __getitem__ method to work as desired.\u001b[39;00m\n\u001b[1;32m   5352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5358\u001b[0m \n\u001b[1;32m   5359\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5360\u001b[0m     getitem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    batch_losses = train(model, train_loader, opt, loss)\n",
    "\n",
    "    # Shuffle data before next epoch\n",
    "    train_loader.shuffle()\n",
    "\n",
    "    val_losses, val_accuracy = validate(model, val_loader, loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}, loss: {np.mean(batch_losses)}, val_loss: {np.mean(val_losses)}, val_accuracy: {val_accuracy}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
